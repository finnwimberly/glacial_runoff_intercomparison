{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d638fc9c-7dd8-4a45-a3ae-6056dd8a387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "import timeit\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202564e6-2df9-4a6d-9dc4-997a54690a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the climate models used\n",
    "modelnames = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585'] #List of all SSPs in PyGEM\n",
    "which_ssp = SSPs[0]\n",
    "\n",
    "alpine_basins = {'RHINE': '6242',\n",
    "                 'RHONE': '6243',\n",
    "                 'PO': '6241',\n",
    "                 'DANUBE':'6202'} ## GRDC Major River Basin identifiers for the 4 alpine basins we can study\n",
    "\n",
    "test_basin = alpine_basins['RHONE'] \n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathPy = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5afff8-206e-4126-bee7-c6ba4ee6ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f24d3ba-2226-40e4-a0f8-547ddeed89d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 10.731557999970391 seconds\n"
     ]
    }
   ],
   "source": [
    "def measure_execution_time():\n",
    "    # Importing all runoff data, taking annual sum, and converting m^3 to km^3\n",
    "    rf_ds = {}\n",
    "    annual_rf_ds = {}\n",
    "    for s, SSP in enumerate(SSPs):\n",
    "        fpath1 = '/R11_runoff_monthly_c2_ba1_1set_2000_2100-{}'.format(SSP)\n",
    "        file_pattern = f'{fpathPy + fpath1}*.nc'\n",
    "        file_list = glob.glob(file_pattern)\n",
    "\n",
    "        datasets = []  # Create an empty list for each SSP\n",
    "        if file_list:\n",
    "            for file in file_list:\n",
    "                with xr.open_dataset(file) as ds:\n",
    "                    ds = ds.glac_runoff_monthly.load()\n",
    "                    datasets.append(ds)\n",
    "\n",
    "            combined_ds = xr.concat(datasets, dim='glacier')  # Concatenate the datasets\n",
    "            rf_ds[SSP] = combined_ds\n",
    "            annual_rf_ds[SSP] = rf_ds[SSP].resample(time='A').sum() * 1e-9\n",
    "\n",
    "    basin_gls = {}\n",
    "    for basin, code in alpine_basins.items():\n",
    "        basin_gls[basin] = select_glaciers_json(code)\n",
    "\n",
    "    # Sorting into basins\n",
    "    basin_datasets = {}\n",
    "    for basin, glacier_list in basin_gls.items():\n",
    "        ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "        basin_datasets[basin] = {}\n",
    "        ds_list = []\n",
    "        for s, SSP in enumerate(SSPs):\n",
    "            try:\n",
    "                ds_filtered = annual_rf_ds[SSP].where(annual_rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "                #print(ds_filtered)\n",
    "                ds_list.append(ds_filtered)\n",
    "            except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "                continue\n",
    "            basin_datasets[basin][SSP] = xr.concat(ds_list, dim='glacier')\n",
    "\n",
    "    # Flipping indexing (to match other models) and summing basins\n",
    "    basin_sums_py = {}\n",
    "    for s, SSP in enumerate(SSPs):\n",
    "        basin_sums_py[SSP] = {}\n",
    "        for basin, glacier_list in basin_gls.items():\n",
    "            basin_sums_py[SSP][basin] = basin_datasets[basin][SSP].sum(dim='glacier')\n",
    "\n",
    "# Measure the execution time\n",
    "execution_time = timeit.timeit(measure_execution_time, number=1)\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
