{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2c3895-7de9-4b66-bf09-fffe2057383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "\n",
    "fpath1 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/Precipitation Analysis/global_ERA5_2000_2022/'\n",
    "regions = ['01', '02', '06', '08', '10', '11', '12', '13', '14', '15', '16', '17', '18']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50f6ed8f-c286-48ac-8c8d-de537f496a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = {'RHINE':'6242', 'RHONE':'6243','PO':'6241', 'DANUBE':'6202', 'TITICACA':'3912', 'SANTA':'3425', \n",
    "            'OCONA':'3418', 'MAJES':'3416', 'MAGDALENA':'3227', 'AMAZON':'3203', 'YELCHO':'3429', \n",
    "            'VALDIVIA':'3428', 'SERRANO':'3426', 'RAPEL':'3423', 'PUELO':'3422', 'PASCUA':'3420', \n",
    "            'PALENA':'3419', 'HUASCO':'3412', 'COPIAPO':'3409', 'CISNES':'3408', 'BIOBIO':'3405', 'BAKER':'3404',\n",
    "            'AZOPARDO':'3403', 'AISEN':'3401', 'SANTA CRUZ':'3244', 'NEGRO':'3232', 'COLORADO':'3212', \n",
    "            'CHICO':'3209', 'TORNEALVEN':'6255', 'THJORSA':'6254', 'OLFUSA':'6237', 'LULEALVEN':'6227', \n",
    "            'KUBAN':'6223', 'KALIXALVEN':'6219', 'GLOMAA':'6213', 'DRAMSELVA':'6209', 'SVARTA':'6110', \n",
    "            'LAGARFLJOT':'6104', 'JOKULSA A FJOLLUM':'6101', 'CLUTHA':'5406', 'YUKON':'4435', 'TAKU':'4431', \n",
    "             'SUSITNA':'4430','STIKINE':'4428', 'SKEENA':'4427','SKAGIT':'4426','NUSHAGAK':'4418','NASS':'4416',\n",
    "            'KUSKOKWIM':'4414','FRASER':'4410', 'COPPER':'4408', 'COLUMBIA':'4406', 'ALSEK':'4401', 'NELSON':'4125', \n",
    "              'MACKENZIE':'4123','COLVILLE':'4110', 'YSYK-KOL':'2919', 'UVS NUUR':'2918', 'TARIM HE':'2914', \n",
    "              'TALAS':'2913', 'LAKE BALKHASH':'2910','HAR US NUUR':'2909', 'CHUY':'2905', 'ARAL SEA':'2902', \n",
    "              'YELLOW RIVER':'2434', 'MEKONG':'2421', 'KAMCHATKA':'2413', 'SALWEEN':'2319', 'IRRAWADDY':'2310', \n",
    "              'INDUS':'2309', 'GANGES':'2306','BRAHMAPUTRA':'2302', 'OB':'2108', 'INDIGIRKA':'2103','YANGTZE' : '2433'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d81869-4ef9-4e80-b7a7-c34ab5e234c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2707adcc-7c8f-4bfa-bc5a-c2a10b2526db",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "for basin, code in basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e077b5-ffc7-4dca-a6b7-509234a4e973",
   "metadata": {},
   "source": [
    "#### Loading in liquid precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0a5377-5ed9-49b9-a6d8-3d098c524d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_comps = {}\n",
    "\n",
    "for region in regions:\n",
    "    fpath2 = 'glac_prec_monthly/'\n",
    "    file_pattern = os.path.join(fpath1, fpath2, f\"{region}/\", f\"R{region}*.nc\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            ds = xr.open_dataset(file)\n",
    "            ds = ds.glac_prec_monthly.load()\n",
    "            datasets.append(ds)\n",
    "    \n",
    "        prcp_comps[region] = xr.concat(datasets, dim='glacier')  # Concatenate the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daf311cf-be17-415a-bf94-3df2a0bf2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "prcp_datasets = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    prcp_datasets[basin] = {}\n",
    "    for r, region in enumerate(regions):\n",
    "        ds_list = []\n",
    "        try:\n",
    "            ds_filtered = prcp_comps[region].where(prcp_comps[region].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            ds_list.append(ds_filtered)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        prcp_datasets[basin][region] = xr.concat(ds_list, dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a28b9563-135d-47e8-b15f-f5253ada3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basin sums separately for each region\n",
    "basin_prcp_sums_individual = {}\n",
    "for basin, glacier_list in basin_gls.items():        \n",
    "    basin_prcp_sums_individual[basin] = {}\n",
    "    for region in regions:\n",
    "        basin_prcp_sums_individual[basin][region] = prcp_datasets[basin][region].sum(dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ebbf0576-dbd1-4b33-afb8-49fc3c1b461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining basin sums for same basins that cross RGI region boundaries\n",
    "basin_prcp_sums = {}\n",
    "for b, basin in enumerate(basins):\n",
    "    basin_prcp_sums[basin] = 0\n",
    "    for r, region in enumerate(regions):\n",
    "        basin_prcp_sums[basin] += basin_prcp_sums_individual[basin].get(region, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4b7ad-4b9c-4a8c-a9b2-1864011514df",
   "metadata": {},
   "source": [
    "#### Loading in solid precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a21f1ff-6d73-48a3-9187-9898bc20bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_comps = {}\n",
    "\n",
    "for region in regions:\n",
    "    fpath2 = 'glac_acc_monthly/'\n",
    "    file_pattern = os.path.join(fpath1, fpath2, f\"{region}/\", f\"R{region}*.nc\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            ds = xr.open_dataset(file)\n",
    "            ds = ds.glac_acc_monthly.load()\n",
    "            datasets.append(ds)\n",
    "    \n",
    "        acc_comps[region] = xr.concat(datasets, dim='glacier')  # Concatenate the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22775e61-b02b-485b-89c9-1da9eb069a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "acc_datasets = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    acc_datasets[basin] = {}\n",
    "    for r, region in enumerate(regions):\n",
    "        ds_list = []\n",
    "        try:\n",
    "            ds_filtered = acc_comps[region].where(acc_comps[region].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            ds_list.append(ds_filtered)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        acc_datasets[basin][region] = xr.concat(ds_list, dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42b12d1d-6ec8-4867-a912-cd101473a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basin sums separately for each region\n",
    "basin_acc_sums_individual = {}\n",
    "for basin, glacier_list in basin_gls.items():        \n",
    "    basin_acc_sums_individual[basin] = {}\n",
    "    for region in regions:\n",
    "        basin_acc_sums_individual[basin][region] = acc_datasets[basin][region].sum(dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a34e0e1b-bfff-4d1a-9903-8231e19758e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining basin sums for same basins that cross RGI region boundaries\n",
    "basin_acc_sums = {}\n",
    "for b, basin in enumerate(basins):\n",
    "    basin_acc_sums[basin] = 0\n",
    "    for r, region in enumerate(regions):\n",
    "        basin_acc_sums[basin] += basin_acc_sums_individual[basin].get(region, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "649eb212-0f83-421d-bf9f-1911a2ec1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining solid and liquid components\n",
    "total_prcp = {}\n",
    "for b, basin in enumerate(basins):\n",
    "    total_prcp[basin] = basin_acc_sums[basin] + basin_prcp_sums[basin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a53fcd1f-8b8a-43b6-a77d-2f714de2874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prcp = {}\n",
    "for b, basin in enumerate(basins):\n",
    "    yearly_sums = total_prcp[basin].resample(time='Y').sum()\n",
    "    avg_prcp[basin] = yearly_sums.sel(time=slice('2000', '2019')).mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2db7f51d-d60a-49aa-b300-2bcf637f5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_list = []\n",
    "\n",
    "# Iterate over basins to extract the mean total precipitation\n",
    "for basin in basins:\n",
    "    # Extract the mean total precipitation for the current basin\n",
    "    mean_total_precipitation = avg_prcp[basin].values.item()\n",
    "    precipitation_list.append(mean_total_precipitation)\n",
    "\n",
    "# Create a pandas Series with basin names as index and mean total precipitation as values\n",
    "precipitation_series = pd.Series(precipitation_list, index=basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5971779f-dacd-472e-a134-f3c9faa1b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Precipitation Analysis/'\n",
    "\n",
    "fname = f\"precip_avgs_Py.csv\"\n",
    "\n",
    "# Define the full path of the output file\n",
    "output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "precipitation_series.to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e5ff6-a02c-43e0-b0c2-7ec57db50508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
