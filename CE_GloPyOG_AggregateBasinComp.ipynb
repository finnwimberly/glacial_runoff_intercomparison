{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a60925c-6bb8-4e62-86b9-39fc29ee391f",
   "metadata": {},
   "source": [
    "## Comparison of GloGEM, PyGEM, and OGGM RGI 11 Runoff Outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4f74b-0fbe-4011-9fc7-01307c850179",
   "metadata": {},
   "source": [
    "This notebook imports and processes GloGEM, PyGEM, and OGGM RGI 11 outputs. Summing glacial runoff by basin, we produce a plot that compares the three models' projected runoff values for each basin by SSP. \n",
    "\n",
    "Last Updated: 6 June 2023 | FFW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f0f48-29d2-4ca3-973d-41ffec199f6b",
   "metadata": {},
   "source": [
    "### Aggregation of GloGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447710ec-e148-4db4-b6e6-e512f97df7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "## Generic the filepath to the main data folder\n",
    "fpath0 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/GloGEM Outputs/CentralEurope/files/'  \n",
    "fpath1 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/GloGEM Outputs/Runoff-intercomparison/GloGEM/Volume' \n",
    "\n",
    "#All of the climate models used\n",
    "modelnames = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0']\n",
    "\n",
    "SSPpaths = ['ssp126','ssp245','ssp370','ssp585']   #Specifiying the SSP\n",
    "#SSPs = ['ssp119','ssp126','ssp245','ssp370','ssp585'] #Use a different path as we have all 5 ssps for volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d81f4-7be9-44b5-aa12-abbda4d1579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_discharges = [[] for _ in SSPpaths]\n",
    "\n",
    "for s, SSPpath in enumerate(SSPpaths):\n",
    "    model_discharges = []\n",
    "    for modelname in modelnames:\n",
    "        temp_df = pd.read_csv(fpath0 + modelname + '/' + SSPpaths[s]  + '/' + 'centraleurope_Discharge_r1.dat', sep='\\s+', header=None, skiprows=1, index_col=0)\n",
    "        model_discharges.append(temp_df)\n",
    "    all_discharges[s] = model_discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8e918-8500-4ce9-9662-ac3c8a4621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_areas = [[] for _ in SSPpaths]\n",
    "\n",
    "for s, SSPpath in enumerate(SSPpaths):\n",
    "    model_areas = []\n",
    "    for modelname in modelnames:\n",
    "        temp_df = pd.read_csv(fpath0 + modelname  + '/' + SSPpaths[s]  + '/' + 'centraleurope_Area_r1.dat', sep='\\s+', index_col=\"ID\")\n",
    "        model_areas.append(temp_df)\n",
    "    all_areas[s] = model_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59501679-4918-4858-9dad-cc0be8898af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(1980, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "new_indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Apply new index and datetime conversion\n",
    "for s, SSPpath_discharges in enumerate(all_discharges):\n",
    "    for m, discharge_df in enumerate(SSPpath_discharges):\n",
    "        all_discharges[s][m].columns = new_indices\n",
    "        all_discharges[s][m].columns = pd.to_datetime(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c587b-aa66-4978-8a43-0d7e76ff0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanding area dataset to match year-month dimension\n",
    "for s in range(len(SSPpaths)):\n",
    "    for i in range(len(all_areas[s])):\n",
    "        all_areas[s][i] = all_areas[s][i][all_areas[s][i].columns.repeat(12)]\n",
    "        \n",
    "for s, areas in enumerate(all_areas):\n",
    "    for i, area in enumerate(areas):\n",
    "        all_areas[s][i].columns = new_indices\n",
    "        all_areas[s][i].columns = pd.to_datetime(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808a2ca-4424-4663-b244-b1542a2fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use our initial area to compute runoff so we fill entire dfs with element 0\n",
    "# We only use one SSP because the initial areas are all the same -- we save time without looping through all\n",
    "# We also convert km^2 to m^2\n",
    "\n",
    "initial_areas = [pd.DataFrame(df.iloc[:, 0].values.repeat(df.shape[1]).reshape(df.shape), index=df.index, columns=df.columns).mul(1e6) for df in all_areas[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99012fa0-eaa5-4b33-8f8e-d2aef78f3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff = {s: {m: None for m in modelnames} for s in SSPpaths} # create nested dictionary indexed by model name and ssp\n",
    "n=0\n",
    "for s in SSPpaths:\n",
    "    i=0\n",
    "    for m in modelnames:\n",
    "        runoff[s][m] = pd.concat([initial_areas[i] * all_discharges[n][i]], axis=1)\n",
    "        i+=1\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33427b-d2a0-4aa4-bef0-0203bb6a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "annualrunoff = {s: {m: None for m in modelnames} for s in SSPpaths}\n",
    "for s, m in itertools.product(SSPpaths, modelnames):\n",
    "    annualrunoff[s][m] = runoff[s][m].transpose().resample('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f8e8-e4c4-48fd-a398-0b99132887d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3cdbe-be9c-4eec-b79a-197f1043fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_basin(basin_RGI_list, runoff_data):\n",
    "    # Create new list to match our RGI formatting\n",
    "    new_basin_list = [int(str(x)[-4:]) for x in basin_RGI_list]\n",
    "    runoff_data = runoff_data.transpose()\n",
    "    \n",
    "    #TODO: create list of glaciers within a basin that are not included in GloGEM output\n",
    "    # Filter new_basin_list to keep only the indexes present in the DataFrame\n",
    "    new_basin_list = [x for x in new_basin_list if x in runoff_data.index]\n",
    "    \n",
    "    # Extract glaciers contained in the list from original df and create a new df\n",
    "    new_df = runoff_data.loc[new_basin_list].copy()\n",
    "    \n",
    "    # Sum the values of the glaciers within the basin\n",
    "    summed_basin_runoff = new_df.sum()\n",
    "    #print(summed_basin_runoff)\n",
    "    \n",
    "    return summed_basin_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d068dc6-230d-4a10-9695-f09575334d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the aggregated basin data\n",
    "alpine_basins = {'RHINE':'6242', 'RHONE':'6243','PO':'6241', 'DANUBE':'6202'} ## GRDC Major River Basin identifiers for the 3 alpine basins we can study\n",
    "modelnames_glo = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0']\n",
    "\n",
    "Rhone_runoff = {s: {m: None for m in modelnames_glo} for s in SSPpaths} # create nested dictionary indexed by model name and ssp\n",
    "Rhine_runoff = {s: {m: None for m in modelnames_glo} for s in SSPpaths} \n",
    "Po_runoff = {s: {m: None for m in modelnames_glo} for s in SSPpaths}\n",
    "Danube_runoff = {s: {m: None for m in modelnames_glo} for s in SSPpaths} \n",
    "\n",
    "for s in SSPpaths:\n",
    "    for m in modelnames_glo:\n",
    "        Rhone_runoff[s][m] = sum_basin(select_glaciers_json(alpine_basins['RHONE']), annualrunoff[s][m]) * 1e-9    #m^3 to km^3\n",
    "        Rhine_runoff[s][m] = sum_basin(select_glaciers_json(alpine_basins['RHINE']), annualrunoff[s][m]) * 1e-9\n",
    "        Po_runoff[s][m] = sum_basin(select_glaciers_json(alpine_basins['PO']), annualrunoff[s][m]) * 1e-9\n",
    "        Danube_runoff[s][m] = sum_basin(select_glaciers_json(alpine_basins['DANUBE']), annualrunoff[s][m]) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b2bc7-3e32-41c9-bf25-1253fe671ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick redefinition that will match PyGEM formatting and make plotting easier later\n",
    "basins = ['RHINE', 'RHONE', 'PO','DANUBE']\n",
    "basin_sums_glo = {s: {b: {} for b in basins} for s in SSPpaths}\n",
    "\n",
    "for s in SSPpaths:\n",
    "    for m in modelnames_glo:\n",
    "        basin_sums_glo[s]['RHINE'][m] = Rhine_runoff[s][m]\n",
    "        basin_sums_glo[s]['RHONE'][m] = Rhone_runoff[s][m]\n",
    "        basin_sums_glo[s]['PO'][m] = Po_runoff[s][m]\n",
    "        basin_sums_glo[s]['DANUBE'][m] = Danube_runoff[s][m]\n",
    "\n",
    "#To calculate multi GCM means and Quartiles we convert to df then calculate across first axis (GCMs)\n",
    "GCM_mean_glo = {}\n",
    "GCM_q1_glo = {}\n",
    "GCM_q3_glo = {}\n",
    "for SSP in SSPpaths:\n",
    "    GCM_mean_glo[SSP] = {}\n",
    "    GCM_q1_glo[SSP] = {}\n",
    "    GCM_q3_glo[SSP] = {}\n",
    "    for b in basins:\n",
    "        GCM_mean_glo[SSP][b] = pd.DataFrame(basin_sums_glo[s][b]).mean(axis=1)\n",
    "        GCM_q1_glo[SSP][b] = pd.DataFrame(basin_sums_glo[s][b]).quantile(q=0.25, axis=1)\n",
    "        GCM_q3_glo[SSP][b] = pd.DataFrame(basin_sums_glo[s][b]).quantile(q=0.75, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18fad1-a883-4176-bc06-2b7cba464834",
   "metadata": {},
   "source": [
    "### Aggregation of PyGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159b67d-0ca2-4c15-9f57-913d2b298cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "#All of the climate models used\n",
    "modelnames_py = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585'] #List of all SSPs in PyGEM\n",
    "which_ssp = SSPs[0]\n",
    "\n",
    "alpine_basins = {'RHINE': '6242',\n",
    "                 'RHONE': '6243',\n",
    "                 'PO': '6241',\n",
    "                 'DANUBE':'6202'} ## GRDC Major River Basin identifiers for the 4 alpine basins we can study\n",
    "\n",
    "test_basin = alpine_basins['RHONE'] \n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathPy = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a75458-1534-4c44-9a6b-59170bcf8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "for basin, code in alpine_basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac464ff0-4830-4986-b389-51cdb216ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, taking annual sum, and converting m^3 to km^3\n",
    "import glob   #use glob to group files by filename similarities (in this case, SSP)\n",
    "\n",
    "rf_ds = {}\n",
    "annual_rf_ds = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    fpath1 = '/R11_runoff_monthly_c2_ba1_1set_2000_2100-{}'.format(SSP)\n",
    "    file_pattern = f'{fpathPy + fpath1}*.nc'\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            with xr.open_dataset(file) as ds:\n",
    "                ds = ds.glac_runoff_monthly.load()\n",
    "                datasets.append(ds)\n",
    "    \n",
    "        combined_ds = xr.concat(datasets, dim='glacier')  # Concatenate the datasets\n",
    "        rf_ds[SSP] = combined_ds\n",
    "        annual_rf_ds[SSP] = rf_ds[SSP].resample(time='A').sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce4835-b9a0-4b4a-96de-f4f9b4c8c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "basin_datasets = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    basin_datasets[basin] = {}\n",
    "    for s, SSP in enumerate(SSPs):\n",
    "        ds_list = []\n",
    "        try:\n",
    "            ds_filtered = annual_rf_ds[SSP].where(annual_rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            ds_list.append(ds_filtered)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        basin_datasets[basin][SSP] = xr.concat(ds_list, dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc05b0e-ad06-448a-b1fc-63c124f33ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping indexing (to match other models) and summing basins\n",
    "basin_sums_py = {}\n",
    "for s, SSP in enumerate(SSPs):        \n",
    "    basin_sums_py[SSP] = {}\n",
    "    for basin, glacier_list in basin_gls.items():\n",
    "        basin_sums_py[SSP][basin] = basin_datasets[basin][SSP].sum(dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff53b4-c886-4825-844b-6600eabcfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute multi GCM means and quartiles\n",
    "GCM_mean_py = {}\n",
    "GCM_q1_py = {}\n",
    "GCM_q3_py = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    which_ssp = SSPs[s]\n",
    "    GCM_mean_py[which_ssp] = {}\n",
    "    GCM_q1_py[which_ssp] = {}\n",
    "    GCM_q3_py[which_ssp] = {}\n",
    "    for basin in basins:\n",
    "        GCM_mean_py[which_ssp][basin] = basin_sums_py[which_ssp][basin].mean(dim = 'model')\n",
    "        GCM_q1_py[which_ssp][basin] = basin_sums_py[which_ssp][basin].quantile(q = 0.25, dim = 'model')\n",
    "        GCM_q3_py[which_ssp][basin] = basin_sums_py[which_ssp][basin].quantile(q = 0.75, dim = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdd650-c616-4761-9edf-5e0fa9dcb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "basins = ['RHINE', 'RHONE', 'PO','DANUBE']\n",
    "\n",
    "yrs_glo = np.arange(1980,2101)\n",
    "yrs_glo_dt = pd.to_datetime([str(y)for y in yrs_glo])\n",
    "\n",
    "colors_glo =  plt.colormaps['Greens']\n",
    "line_colors_glo = colors_glo(np.linspace(0.2, 0.6, num = 12))\n",
    "glo_cycler = cycler(color = line_colors_glo)\n",
    "\n",
    "colors_py =  plt.colormaps['Purples']\n",
    "line_colors_py = colors_py(np.linspace(0.2, 0.6,num = 12))\n",
    "py_cycler = cycler(color = line_colors_py)\n",
    "\n",
    "ssp_label_pos = [1.9, 4.73, 1.45, 2.0]\n",
    "\n",
    "#Plotting all data\n",
    "fig, axs = plt.subplots(len(scenarios), 4, figsize=(12, 10), sharex=True)\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    which_ssp = SSPs[s]\n",
    "    for b, basin in enumerate(basins):\n",
    "        for m in modelnames_glo:\n",
    "            axs[s, b].plot(yrs_glo_dt, basin_sums_glo[which_ssp][basin][m], color=axs[s, b].set_prop_cycle(glo_cycler), alpha = 0.25)\n",
    "        axs[s,b].plot(yrs_glo_dt, GCM_mean_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.9)\n",
    "        axs[s,b].plot(yrs_glo_dt, GCM_q1_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "        axs[s,b].plot(yrs_glo_dt, GCM_q3_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "        axs[s,b].fill_between(yrs_glo_dt, GCM_q1_glo[which_ssp][basin], GCM_q3_glo[which_ssp][basin], color = 'green')\n",
    "        axs[s, b].set(xlim=(pd.to_datetime('2000-01-01'), pd.to_datetime('2100-01-01')))\n",
    "\n",
    "        basin_sums_py[which_ssp][basin].plot(hue='model', ax=axs[s, b], color=axs[s, b].set_prop_cycle(py_cycler), alpha = 0.25, add_legend=False)\n",
    "        GCM_mean_py[which_ssp][basin].plot(hue='model', ax=axs[s, b], color = 'purple', linewidth = 0.9, add_legend=False)\n",
    "        GCM_q1_py[which_ssp][basin].plot(hue='model', ax=axs[s, b], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "        GCM_q3_py[which_ssp][basin].plot(hue='model', ax=axs[s, b], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "        axs[s,b].fill_between(yrs_glo_dt[20::], GCM_q1_py[which_ssp][basin], GCM_q3_py[which_ssp][basin], color = 'Purple')\n",
    "        axs[s,b].set(title = '')\n",
    "\n",
    "        #Setting x and y labels and making y limits uniform within basins\n",
    "        if s == 3:\n",
    "            for sub_b in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[s, sub_b].set_xlabel('Year')\n",
    "                axs[s, sub_b].set_xticks([pd.to_datetime('2020'),pd.to_datetime('2040'), pd.to_datetime('2060'), pd.to_datetime('2080')], [2020, 2040, 2060, 2080])\n",
    "        else:\n",
    "            axs[s, b].set_xlabel(None)\n",
    "            \n",
    "        if b == 0:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[sub_s, b].set(ylim = (0.4,2.1))\n",
    "                if sub_s == 2:\n",
    "                    axs[sub_s, b].set_ylabel(r'Multi-GCM Runoff Mean and Quartiles $[km^3]$', y=1.1)\n",
    "            else:\n",
    "                axs[s, b].set_ylabel(None)\n",
    "            \n",
    "        if b == 1:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[sub_s, b].set(ylim = (0.8,5.2))\n",
    "                axs[s, b].set_ylabel(None)\n",
    "        if b == 2:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[sub_s, b].set_yticks([0.5, 1.0, 1.5]) \n",
    "                axs[sub_s, b].set(ylim = (0.3,1.6))\n",
    "                axs[s, b].set_ylabel(None)\n",
    "        if b == 3:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[sub_s, b].set(ylim = (0.4,2.2))\n",
    "                axs[s, b].set_ylabel(None)\n",
    "\n",
    "        axs[s, b].text(pd.to_datetime('2070-01-01'), ssp_label_pos[b], SSP)\n",
    "\n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM')       \n",
    "axs[0,0].legend(handles=[green_patch, purple_patch], bbox_to_anchor=(2.8, 1.48), ncol=2)\n",
    "\n",
    "#plt.subplots_adjust(hspace = 0.5)\n",
    "plt.suptitle('GloGEM and PyGEM Runoff Projections for Major Central European River Basins')\n",
    "plt.title('Rhine River Basin                 Rhone River Basin                    Po River Basin                   Danube River Basin', x=-1.28, y=4.72)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915200b-374f-404b-a9d0-fda9b8e74490",
   "metadata": {},
   "source": [
    "### Introducing OGGM Runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888f950-d37b-4d39-9fb7-dc895d6fd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the climate models used\n",
    "modelnames_OG = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CESM2', 'CESM2-WACCM', 'CMCC-CM2-SR5','EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', 'INM-CM4-8',\n",
    "               'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM', 'TaiESM1']\n",
    "\n",
    "# CMCC-CM2-SR5 & TaiESM1 only hold values for ssp585––this is model list without those GCMS\n",
    "modelnames_OG_trimmed = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', 'INM-CM4-8',\n",
    "               'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathOG = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/OGGM Outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb82c9-ae36-4d8e-90fa-322ffa5544a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, OGGM is grouped by basin\n",
    "rf_ds = {}\n",
    "for basin, code in alpine_basins.items():\n",
    "    fpath_basin = 'lschuster/{}'.format(code)\n",
    "    #print(f'{fpathOG + fpath_basin} (1)/*.nc')\n",
    "    with xr.open_mfdataset(f'{fpathOG + fpath_basin} (1)/*.nc') as ds:\n",
    "        ds = ds.runoff.load()\n",
    "    rf_ds[basin] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb7ff6-4d1d-4058-98af-92ab7b85e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing individual glacier runoff into basin totals and converting kg to km^3\n",
    "basin_rf_OG = {}\n",
    "for basin, code in alpine_basins.items():\n",
    "    basin_rf_OG[basin] = rf_ds[basin].sum(dim = 'rgi_id') * 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf56a4-a51b-4d33-8fde-d6ead6af7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dict of GloPy format\n",
    "basins = ['RHINE', 'RHONE', 'PO', 'DANUBE']\n",
    "basin_sums_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    which_ssp = SSPs[s]\n",
    "    basin_sums_OG[which_ssp] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        basin_sums_OG[which_ssp][basin] = basin_rf_OG[basin].sel(scenario = which_ssp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131acfb-f1ca-4c72-af1a-a78d5e92c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting it looks like some GCMs contain all-zero values, like:\n",
    "basin_sums_OG['ssp126']['DANUBE'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901a217-eace-442e-8a9d-8d425221340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing these GCMs for ALL SSPs--doing even 585 as these two are not included...\n",
    "#... in Glo or Py so not only makeds OOGM easier but maintains GCM consistency in analysis\n",
    "trimmed_basin_sums_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    which_ssp = SSPs[s]\n",
    "    trimmed_basin_sums_OG[which_ssp] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        trimmed_basin_sums_OG[which_ssp][basin] = xr.concat([basin_sums_OG[which_ssp][basin][0:4], basin_sums_OG[which_ssp][basin][5:-1]], dim='gcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a83c1e-ef6d-48c6-848a-e5f5f6717313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute multi GCM means and quartiles for OGGM\n",
    "GCM_mean_OG = {}\n",
    "GCM_q1_OG = {}\n",
    "GCM_q3_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    which_ssp = SSPs[s]\n",
    "    GCM_mean_OG[which_ssp] = {}\n",
    "    GCM_q1_OG[which_ssp] = {}\n",
    "    GCM_q3_OG[which_ssp] = {}\n",
    "    for basin in basins:\n",
    "        GCM_mean_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].mean(dim = 'gcm')\n",
    "        GCM_q1_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].quantile(q = 0.25, dim = 'gcm')\n",
    "        GCM_q3_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].quantile(q = 0.75, dim = 'gcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc97b9-9121-4a89-a36d-719908779fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot setup\n",
    "from cycler import cycler\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "basins = ['RHINE', 'RHONE', 'PO','DANUBE']\n",
    "basinstext = ['Rhine', 'Rhone', 'Po','Danube']\n",
    "\n",
    "yrs_glo = np.arange(1980,2101)\n",
    "yrs_glo_dt = pd.to_datetime([str(y)for y in yrs_glo])\n",
    "\n",
    "colors_glo =  plt.colormaps['Greens']\n",
    "line_colors_glo = colors_glo(np.linspace(0.2, 0.6, num = 12))\n",
    "glo_cycler = cycler(color = line_colors_glo)\n",
    "\n",
    "colors_py =  plt.colormaps['Purples']\n",
    "line_colors_py = colors_py(np.linspace(0.2, 0.6,num = 12))\n",
    "py_cycler = cycler(color = line_colors_py)\n",
    "\n",
    "colors_OG =  plt.colormaps['Blues']\n",
    "line_colors_OG = colors_OG(np.linspace(0.2, 0.6,num = 12))\n",
    "OG_cycler = cycler(color = line_colors_OG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455e612-20d2-47c6-b535-65a673a86198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct for GloGEM hydro vs regular year indexing???\n",
    "start_date = datetime.date(1979, 10, 1)\n",
    "end_date = datetime.date(2100, 9, 1)\n",
    "yrs = pd.date_range(start_date, end_date, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd1fff-e347-4424-9351-fb693a557004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same plot as above with OGGM data added\n",
    "#Also flipping axes so that l to r reads as one basin with increasing scenario severity \n",
    "#Plotting all data\n",
    "fig, axs = plt.subplots(len(scenarios), 4, figsize=(12, 10), sharex=True)\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    which_ssp = SSPs[s]\n",
    "    for b, basin in enumerate(basins):\n",
    "\n",
    "        #OG won't plot with built-in ds.plot()\n",
    "        #Trim last value as it goes to zero\n",
    "        for m, model in enumerate(modelnames_OG_trimmed):\n",
    "            axs[b,s].plot(yrs_glo_dt[20:-1], trimmed_basin_sums_OG[which_ssp][basin][:,0:-1].sel(gcm = modelnames_OG_trimmed[m]), color = 'dodgerblue', alpha = 0.15)\n",
    "        axs[b,s].plot(yrs_glo_dt[20:-1], GCM_mean_OG[which_ssp][basin][0:-1], color = 'royalblue', linewidth = 0.9)\n",
    "        axs[b,s].plot(yrs_glo_dt[20:-1], GCM_q1_OG[which_ssp][basin][0:-1], color = 'royalblue', linewidth = 0.4)\n",
    "        axs[b,s].plot(yrs_glo_dt[20:-1], GCM_q3_OG[which_ssp][basin][0:-1], color = 'royalblue', linewidth = 0.4)\n",
    "        axs[b,s].fill_between(yrs_glo_dt[20:-1], GCM_q1_OG[which_ssp][basin][0:-1], GCM_q3_OG[which_ssp][basin][0:-1], color = 'dodgerblue', alpha = 0.5)\n",
    "\n",
    "        #Trim first value as it is incomplete hydrological year\n",
    "        for m in modelnames_glo:\n",
    "            axs[b, s].plot(yrs_glo_dt, basin_sums_glo[which_ssp][basin][m], color=axs[b, s].set_prop_cycle(glo_cycler), alpha = 0.25)\n",
    "        axs[b,s].plot(yrs_glo_dt, GCM_mean_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.9)\n",
    "        axs[b,s].plot(yrs_glo_dt, GCM_q1_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "        axs[b,s].plot(yrs_glo_dt, GCM_q3_glo[which_ssp][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "        axs[b,s].fill_between(yrs_glo_dt, GCM_q1_glo[which_ssp][basin], GCM_q3_glo[which_ssp][basin], color = 'green')\n",
    "        axs[b, s].set(xlim=(pd.to_datetime('2000-01-01'), pd.to_datetime('2100-01-01')))\n",
    "\n",
    "        basin_sums_py[which_ssp][basin].plot(hue='model', ax=axs[b, s], color=axs[b, s].set_prop_cycle(py_cycler), alpha = 0.25, add_legend=False)\n",
    "        GCM_mean_py[which_ssp][basin].plot(hue='model', ax=axs[b, s], color = 'purple', linewidth = 0.9, add_legend=False)\n",
    "        GCM_q1_py[which_ssp][basin].plot(hue='model', ax=axs[b, s], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "        GCM_q3_py[which_ssp][basin].plot(hue='model', ax=axs[b, s], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "        axs[b,s].fill_between(yrs_glo_dt[20::], GCM_q1_py[which_ssp][basin], GCM_q3_py[which_ssp][basin], color = 'Purple')\n",
    "        axs[b,s].set(title = '')\n",
    "\n",
    "        #Make mean more clear for RHONE, which overlaps significantly w Glo\n",
    "        axs[b,s].plot(yrs_glo_dt[20:-1], GCM_mean_OG[which_ssp][basin][0:-1], color = 'royalblue', linewidth = 0.9)\n",
    "\n",
    "        #Setting x and y labels and making y limits uniform within basins\n",
    "        if b == 3:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[b, sub_s].set_xlabel('Year')\n",
    "                axs[b, sub_s].set_xticks([pd.to_datetime('2020'),pd.to_datetime('2040'), pd.to_datetime('2060'), pd.to_datetime('2080')], [2020, 2040, 2060, 2080])\n",
    "        else:\n",
    "            axs[b, s].set_xlabel(None) \n",
    "        if b == 0:\n",
    "            for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                axs[b, sub_s].set_yticks([0.5, 1.0, 1.5, 2.0, 2.5]) \n",
    "                axs[b, sub_s].set(ylim = (0.4,2.6))\n",
    "        if b == 1:\n",
    "            for sub_s in range(4): \n",
    "                y_ticks = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "                y_tick_labels = [f'{tick:.1f}' for tick in y_ticks] \n",
    "                axs[b, sub_s].set_yticks(y_ticks)\n",
    "                axs[b, sub_s].set_yticklabels(y_tick_labels)\n",
    "                axs[b, sub_s].set(ylim = (0.8,5.5))\n",
    "        if b == 2:                                                                   #Setting y-limits for each basin\n",
    "            for sub_s in range(4):  \n",
    "                axs[b, sub_s].set_yticks([0.5, 1.0, 1.5, 2.0]) \n",
    "                axs[b, sub_s].set(ylim = (0.3,2.1))\n",
    "        if b == 3:\n",
    "            for sub_s in range(4):  \n",
    "                axs[b, sub_s].set(ylim = (0.4,2.6))\n",
    "        if s == 0:                                                                    #Setting basin labels\n",
    "            for sub_b in range(4):\n",
    "                axs[sub_b,s].set_ylabel(basinstext[sub_b]+ r' Runoff $[km^3]$')\n",
    "        if s != 0:\n",
    "            axs[b, s].set_ylabel(None)\n",
    "\n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "axs[0,0].legend(handles=[green_patch, purple_patch, blue_patch], bbox_to_anchor=(3.15, 1.46), ncol=3)\n",
    "\n",
    "plt.suptitle('GloGEM, PyGEM, and OGGM Runoff Projections for Major Central European River Basins', x=0.52)\n",
    "plt.title('SSP 126                                 SSP 245                                SSP 370                                 SSP 585', x=-1.3, y=4.66) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1c416-c0eb-4079-af84-c8afd440c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
