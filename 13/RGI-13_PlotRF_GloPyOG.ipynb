{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bbdd66-2ce1-4711-be0e-1e5807772834",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb115a1-b52e-4869-9108-014a6a3bd28b",
   "metadata": {},
   "source": [
    "This notebook creates visuals of the runoff data for all 3 Models. The data has been loaded elsewhere and converted to a locally saved CSV to the address memory capacity issues encountered when processing large RGI regions. \n",
    "\n",
    "Last edited: Dec 7, 2023 | FFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c9b2c-0195-4abb-a877-3811d4b01f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "from cycler import cycler\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedbd62-1033-4c4b-a272-fd2d50f4d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_models = ['GloGEM', 'OGGM', 'PyGEM']\n",
    "\n",
    "gmodels_2regions = ['GloGEM', 'PyGEM']\n",
    "\n",
    "modelnames_all = ['BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', \n",
    "                  'INM-CM4-8', 'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basins = ['YSYK-KOL', 'TARIM HE', 'TALAS', 'LAKE BALKHASH', 'CHUY', 'ARAL SEA', 'YELLOW RIVER', 'MEKONG', \n",
    "          'SALWEEN', 'INDUS', 'BRAHMAPUTRA', 'YANGTZE']\n",
    "\n",
    "basins_14 = ['TARIM HE', 'ARAL SEA', 'INDUS']\n",
    "\n",
    "basins_15 = ['SALWEEN', 'BRAHMAPUTRA', 'YANGTZE']\n",
    "\n",
    "basinstext = ['Ysyk-Kol', 'Tarim He', 'Talas', 'Lake Balkhash', 'Chuy', 'Aral Sea', 'Yellow River', \n",
    "              'Mekong', 'Salween', 'Indus', 'Brahmaputra', 'Yangtze']\n",
    "\n",
    "fpath0 = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Load Separate/RGI 13/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbccdb-4cbc-4430-b1f8-f2f2f7e445bb",
   "metadata": {},
   "source": [
    "#### Importing CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c6549-2b3d-46b4-b1d2-8a9a7a90bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "new_indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66e5c4-2ebe-486a-bf17-abebc94725fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data, applying datetime indices, and creating annual sum dfs\n",
    "all_rf_data = {}\n",
    "all_rf_data_annual = {}\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    all_rf_data[gmodel] = {}\n",
    "    all_rf_data_annual[gmodel] = {}\n",
    "    fpath = fpath0 + gmodel + '/'\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        all_rf_data[gmodel][SSP] = {}\n",
    "        all_rf_data_annual[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins):\n",
    "            all_rf_data[gmodel][SSP][basin] = {}\n",
    "            all_rf_data_annual[gmodel][SSP][basin] = {}\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                fname = f\"runoff_{GCM}_{SSP}_{basin}.csv\"\n",
    "                temp_df = pd.read_csv(fpath + fname, index_col = 0)\n",
    "                all_rf_data[gmodel][SSP][basin][GCM] = temp_df\n",
    "                all_rf_data[gmodel][SSP][basin][GCM].index = new_indices\n",
    "                all_rf_data[gmodel][SSP][basin][GCM].index = pd.to_datetime(new_indices)\n",
    "                all_rf_data_annual[gmodel][SSP][basin][GCM] = all_rf_data[gmodel][SSP][basin][GCM].resample('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1553e5b-0dbb-49a7-8baa-2d326b254104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in data for glacier actually located in RGI 14\n",
    "all_rf_data_14 = {}\n",
    "all_rf_data_annual_14 = {}\n",
    "for g, gmodel in enumerate(gmodels_2regions):\n",
    "    all_rf_data_14[gmodel] = {}\n",
    "    all_rf_data_annual_14[gmodel] = {}\n",
    "    fpath = fpath0 + gmodel + '/'\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        all_rf_data_14[gmodel][SSP] = {}\n",
    "        all_rf_data_annual_14[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins_14):\n",
    "            all_rf_data_14[gmodel][SSP][basin] = {}\n",
    "            all_rf_data_annual_14[gmodel][SSP][basin] = {}\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                fname = f\"runoff_fromRGI14_{GCM}_{SSP}_{basin}.csv\"\n",
    "                temp_df = pd.read_csv(fpath + fname, index_col = 0)\n",
    "                all_rf_data_14[gmodel][SSP][basin][GCM] = temp_df\n",
    "                all_rf_data_14[gmodel][SSP][basin][GCM].index = new_indices\n",
    "                all_rf_data_14[gmodel][SSP][basin][GCM].index = pd.to_datetime(new_indices)\n",
    "                all_rf_data_annual_14[gmodel][SSP][basin][GCM] = all_rf_data_14[gmodel][SSP][basin][GCM].resample('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5011d-2cc9-4534-a08e-a03be78929ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in data for glacier actually located in RGI 15\n",
    "all_rf_data_15 = {}\n",
    "all_rf_data_annual_15 = {}\n",
    "for g, gmodel in enumerate(gmodels_2regions):\n",
    "    all_rf_data_15[gmodel] = {}\n",
    "    all_rf_data_annual_15[gmodel] = {}\n",
    "    fpath = fpath0 + gmodel + '/'\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        all_rf_data_15[gmodel][SSP] = {}\n",
    "        all_rf_data_annual_15[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins_15):\n",
    "            all_rf_data_15[gmodel][SSP][basin] = {}\n",
    "            all_rf_data_annual_15[gmodel][SSP][basin] = {}\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                fname = f\"runoff_fromRGI15_{GCM}_{SSP}_{basin}.csv\"\n",
    "                temp_df = pd.read_csv(fpath + fname, index_col = 0)\n",
    "                all_rf_data_15[gmodel][SSP][basin][GCM] = temp_df\n",
    "                all_rf_data_15[gmodel][SSP][basin][GCM].index = new_indices\n",
    "                all_rf_data_15[gmodel][SSP][basin][GCM].index = pd.to_datetime(new_indices)\n",
    "                all_rf_data_annual_15[gmodel][SSP][basin][GCM] = all_rf_data_15[gmodel][SSP][basin][GCM].resample('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55835087-59f3-49ec-b237-55064bc39d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining glacier runoff sums for basins with glaciers in RGI region 14\n",
    "combined_1314_rf_data = {}\n",
    "combined_1314_rf_data_annual = {}\n",
    "\n",
    "for g, gmodel in enumerate(gmodels_2regions):\n",
    "    combined_1314_rf_data[gmodel] = {}\n",
    "    combined_1314_rf_data_annual[gmodel] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        combined_1314_rf_data[gmodel][SSP] = {}\n",
    "        combined_1314_rf_data_annual[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins_14):\n",
    "            combined_1314_rf_data[gmodel][SSP][basin] = {}\n",
    "            combined_1314_rf_data_annual[gmodel][SSP][basin] = {}  # Corrected this line\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                # Concatenate the dataframes along axis=0 (rows) and perform element-wise summation\n",
    "                combined_df = pd.concat([all_rf_data[gmodel][SSP][basin][GCM], all_rf_data_14[gmodel][SSP][basin][GCM]], axis = 0)\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum()\n",
    "                combined_1314_rf_data[gmodel][SSP][basin][GCM] = combined_df\n",
    "\n",
    "                # Concatenate the annual dataframes along axis=0 (rows) and perform element-wise summation\n",
    "                combined_annual_df = pd.concat([all_rf_data_annual_14[gmodel][SSP][basin][GCM], all_rf_data_annual[gmodel][SSP][basin][GCM]], axis = 0)\n",
    "                combined_annual_df = combined_annual_df.groupby(combined_annual_df.index).sum()\n",
    "                combined_1314_rf_data_annual[gmodel][SSP][basin][GCM] = combined_annual_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0d356-e1ec-4f6a-aea5-fb1c9b85f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in 15 as well\n",
    "combined_1315_rf_data = {}\n",
    "combined_1315_rf_data_annual = {}\n",
    "\n",
    "for g, gmodel in enumerate(gmodels_2regions):\n",
    "    combined_1315_rf_data[gmodel] = {}\n",
    "    combined_1315_rf_data_annual[gmodel] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        combined_1315_rf_data[gmodel][SSP] = {}\n",
    "        combined_1315_rf_data_annual[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins_15):\n",
    "            combined_1315_rf_data[gmodel][SSP][basin] = {}\n",
    "            combined_1315_rf_data_annual[gmodel][SSP][basin] = {}  # Corrected this line\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                # Concatenate the dataframes along axis=0 (rows) and perform element-wise summation\n",
    "                combined_df = pd.concat([all_rf_data[gmodel][SSP][basin][GCM], all_rf_data_15[gmodel][SSP][basin][GCM]], axis = 0)\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum()\n",
    "                combined_1315_rf_data[gmodel][SSP][basin][GCM] = combined_df\n",
    "\n",
    "                # Concatenate the annual dataframes along axis=0 (rows) and perform element-wise summation\n",
    "                combined_annual_df = pd.concat([all_rf_data_annual[gmodel][SSP][basin][GCM], all_rf_data_annual_15[gmodel][SSP][basin][GCM]], axis = 0)\n",
    "                combined_annual_df = combined_annual_df.groupby(combined_annual_df.index).sum()\n",
    "                combined_1315_rf_data_annual[gmodel][SSP][basin][GCM] = combined_annual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc18b3-c9ba-44ec-8639-29b064d5f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCM_mean = {}\n",
    "GCM_q1 = {}\n",
    "GCM_q3 = {}\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    GCM_mean[gmodel] = {}\n",
    "    GCM_q1[gmodel] = {}\n",
    "    GCM_q3[gmodel] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        GCM_mean[gmodel][SSP] = {}\n",
    "        GCM_q1[gmodel][SSP] = {}\n",
    "        GCM_q3[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins):\n",
    "            GCM_mean[gmodel][SSP][basin] = {}\n",
    "            GCM_q1[gmodel][SSP][basin] = {}\n",
    "            GCM_q3[gmodel][SSP][basin] = {}\n",
    "            if basin in basins_14 and gmodel != 'OGGM':\n",
    "                df_dict = combined_1314_rf_data_annual[gmodel][SSP][basin]\n",
    "            elif basin in basins_15 and gmodel != 'OGGM':\n",
    "                df_dict = combined_1315_rf_data_annual[gmodel][SSP][basin]\n",
    "            else:\n",
    "                df_dict = all_rf_data_annual[gmodel][SSP][basin]\n",
    "\n",
    "            df_mean = pd.concat(df_dict.values(), axis=1).mean(axis=1)\n",
    "            GCM_mean[gmodel][SSP][basin] = df_mean\n",
    "\n",
    "            df_q1 = pd.concat(df_dict.values(), axis=1).quantile(q=0.25, axis=1)\n",
    "            GCM_q1[gmodel][SSP][basin] = df_q1\n",
    "\n",
    "            df_q3 = pd.concat(df_dict.values(), axis=1).quantile(q=0.75, axis=1)\n",
    "            GCM_q3[gmodel][SSP][basin] = df_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acf19d-526d-4885-a80e-8fb4e1eb3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating time values and color schemes\n",
    "yrs = np.arange(2000, 2101)\n",
    "yrs_dt = pd.to_datetime([str(y) for y in yrs])\n",
    "\n",
    "colorschemes = {}\n",
    "\n",
    "colors_glo =  plt.colormaps['Greens']\n",
    "line_colors_glo = colors_glo(np.linspace(0.2, 0.6, num = 12))\n",
    "glo_cycler = cycler(color = line_colors_glo)\n",
    "colorschemes['GloGEM'] = glo_cycler\n",
    "\n",
    "colors_OG =  plt.colormaps['Blues']\n",
    "line_colors_OG = colors_OG(np.linspace(0.2, 0.6,num = 12))\n",
    "OG_cycler = cycler(color = line_colors_OG)\n",
    "colorschemes['OGGM'] = OG_cycler\n",
    "\n",
    "colors_py =  plt.colormaps['Purples']\n",
    "line_colors_py = colors_py(np.linspace(0.2, 0.6,num = 12))\n",
    "py_cycler = cycler(color = line_colors_py)\n",
    "colorschemes['PyGEM'] = py_cycler\n",
    "\n",
    "colors = ['darkgreen', 'royalblue', 'purple']\n",
    "fill_colors = ['green', 'dodgerblue', 'purple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ead5e-9323-40dd-aeb3-6b14b4dba9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(basins), len(scenarios), figsize=(10, 2.4*len(basins)), sharex =True)\n",
    "\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        for b, basin in enumerate(basins):\n",
    "            for m, GCM in enumerate(modelnames_all):\n",
    "                if basin not in basins_14 and basin not in basins_15 or gmodel == 'OGGM':\n",
    "                    axs[b,s].plot(yrs_dt[0:-1], all_rf_data_annual[gmodel][SSP][basin][GCM][0:-1], color=axs[b, s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                    axs[b,s].plot(yrs_dt[0:-1], GCM_mean[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.9)\n",
    "                    axs[b,s].plot(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].plot(yrs_dt[0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].fill_between(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color = fill_colors[g])\n",
    "                \n",
    "                if basin in basins_14 and gmodel!= 'OGGM':\n",
    "                    axs[b,s].plot(yrs_dt, combined_1314_rf_data_annual[gmodel][SSP][basin][GCM], color=axs[b, s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_mean[gmodel][SSP][basin], color = colors[g], linewidth = 0.9)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_q1[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_q3[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].fill_between(yrs_dt, GCM_q1[gmodel][SSP][basin], GCM_q3[gmodel][SSP][basin], color = fill_colors[g])\n",
    "\n",
    "                if basin in basins_15 and gmodel!= 'OGGM':\n",
    "                    axs[b,s].plot(yrs_dt, combined_1315_rf_data_annual[gmodel][SSP][basin][GCM], color=axs[b, s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_mean[gmodel][SSP][basin], color = colors[g], linewidth = 0.9)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_q1[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].plot(yrs_dt, GCM_q3[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                    axs[b,s].fill_between(yrs_dt, GCM_q1[gmodel][SSP][basin], GCM_q3[gmodel][SSP][basin], color = fill_colors[g])\n",
    "                \n",
    "                axs[b,s].set(xlim=(pd.to_datetime('2000-01-01'), pd.to_datetime('2100-01-01')))\n",
    "\n",
    "         #Setting x and y labels and making y limits uniform within basins\n",
    "                if b == (len(basins)-1):\n",
    "                    for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                        axs[b, sub_s].set_xlabel('Year')\n",
    "                        axs[b, sub_s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "                else:\n",
    "                    axs[b, s].set_xlabel(None) \n",
    "                \n",
    "                if s == 0:                                                                    #Setting basin labels\n",
    "                    for sub_b in range(len(basins)):\n",
    "                        axs[sub_b,s].set_ylabel(basinstext[sub_b]+ r' $[km^3]$')\n",
    "                if s != 0:\n",
    "                    axs[b, s].set_ylabel(None)\n",
    "                    axs[b, s].set_yticklabels('')\n",
    "\n",
    "for b in range(len(basins)):         #Limits determined by max/min between all GCMs\n",
    "    row_min = np.inf\n",
    "    row_max = -np.inf\n",
    "    for s in range(len(scenarios)):\n",
    "        data_min = np.min(axs[b, s].get_ybound()[0])\n",
    "        data_max = np.max(axs[b, s].get_ybound()[1])\n",
    "        if data_min < row_min:\n",
    "            row_min = data_min\n",
    "        if data_max > row_max:\n",
    "            row_max = data_max\n",
    "    for s in range(len(scenarios)):\n",
    "        axs[b, s].set_ylim(row_min, row_max)\n",
    "\n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "\n",
    "axs[0,0].legend(handles=[green_patch, purple_patch, blue_patch], bbox_to_anchor=(3.15, (0.118*len(basins))), ncol=3)\n",
    "\n",
    "plt.suptitle('GloGEM, PyGEM, and OGGM Runoff Projections for Southern Asian River Basins', x=0.5, y=0.91)\n",
    "plt.title('SSP 126                            SSP 245                           SSP 370                            SSP 585', x=-1.3, y=(1.181* len(basins))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fc69b-dced-42e0-8016-7959937e4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a single basin name\n",
    "basin = 'INDUS'\n",
    "basinstext = 'Indus'\n",
    "\n",
    "# Create a 1-row, 4-column subplot arrangement\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 1.6), sharex=True)\n",
    "\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    for g, gmodel in enumerate(glacier_models):\n",
    "        for m, GCM in enumerate(modelnames_all):\n",
    "            if basin not in basins_14 and basin not in basins_15 or gmodel == 'OGGM':\n",
    "                    axs[s].plot(yrs_dt[0:-1], all_rf_data_annual[gmodel][SSP][basin][GCM][0:-1], color=axs[s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                    axs[s].plot(yrs_dt[0:-1], GCM_mean[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.9)\n",
    "                    axs[s].plot(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.4)\n",
    "                    axs[s].plot(yrs_dt[0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color = colors[g], linewidth = 0.4)\n",
    "                    axs[s].fill_between(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color = fill_colors[g])\n",
    "                \n",
    "            if basin in basins_14 and gmodel!= 'OGGM':\n",
    "                axs[s].plot(yrs_dt, combined_1314_rf_data_annual[gmodel][SSP][basin][GCM], color=axs[s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                axs[s].plot(yrs_dt, GCM_mean[gmodel][SSP][basin], color = colors[g], linewidth = 0.9)\n",
    "                axs[s].plot(yrs_dt, GCM_q1[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                axs[s].plot(yrs_dt, GCM_q3[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                axs[s].fill_between(yrs_dt, GCM_q1[gmodel][SSP][basin], GCM_q3[gmodel][SSP][basin], color = fill_colors[g])\n",
    "\n",
    "            if basin in basins_15 and gmodel!= 'OGGM':\n",
    "                axs[s].plot(yrs_dt, combined_1315_rf_data_annual[gmodel][SSP][basin][GCM], color=axs[s].set_prop_cycle(colorschemes[gmodel]), alpha = 0.25)\n",
    "                axs[s].plot(yrs_dt, GCM_mean[gmodel][SSP][basin], color = colors[g], linewidth = 0.9)\n",
    "                axs[s].plot(yrs_dt, GCM_q1[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                axs[s].plot(yrs_dt, GCM_q3[gmodel][SSP][basin], color = colors[g], linewidth = 0.4)\n",
    "                axs[s].fill_between(yrs_dt, GCM_q1[gmodel][SSP][basin], GCM_q3[gmodel][SSP][basin], color = fill_colors[g])\n",
    "            \n",
    "            # if gmodel == 'OGGM':\n",
    "            #     axs[s].plot(yrs_dt[0:-1], all_rf_data_annual[gmodel][SSP][basin][GCM][0:-1], color=axs[s].set_prop_cycle(colorschemes[gmodel]), alpha=0.25)\n",
    "            #     axs[s].plot(yrs_dt[0:-1], GCM_mean[gmodel][SSP][basin][0:-1], color=colors[g], linewidth=0.9)\n",
    "            #     axs[s].plot(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], color=colors[g], linewidth=0.4)\n",
    "            #     axs[s].plot(yrs_dt[0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color=colors[g], linewidth=0.4)\n",
    "            #     axs[s].fill_between(yrs_dt[0:-1], GCM_q1[gmodel][SSP][basin][0:-1], GCM_q3[gmodel][SSP][basin][0:-1], color=fill_colors[g])\n",
    "            # else:\n",
    "            #     axs[s].plot(yrs_dt, all_rf_data_annual[gmodel][SSP][basin][GCM], color=axs[s].set_prop_cycle(colorschemes[gmodel]), alpha=0.25)\n",
    "            #     axs[s].plot(yrs_dt, GCM_mean[gmodel][SSP][basin], color=colors[g], linewidth=0.9)\n",
    "            #     axs[s].plot(yrs_dt, GCM_q1[gmodel][SSP][basin], color=colors[g], linewidth=0.4)\n",
    "            #     axs[s].plot(yrs_dt, GCM_q3[gmodel][SSP][basin], color=colors[g], linewidth=0.4)\n",
    "            #     axs[s].fill_between(yrs_dt, GCM_q1[gmodel][SSP][basin], GCM_q3[gmodel][SSP][basin], color=fill_colors[g])\n",
    "            # axs[s].set(xlim=(pd.to_datetime('2000-01-01'), pd.to_datetime('2100-01-01')))\n",
    "\n",
    "            # Setting x and y labels\n",
    "            #axs[s].set_xlabel('Year')\n",
    "            axs[s].set_xticks([pd.to_datetime('2025'), pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [' ', ' ', ' ', ' '])\n",
    "\n",
    "             #axs[s].set_xlabel('Year')\n",
    "            #axs[s].set_xticks([pd.to_datetime('2025-01-01'), pd.to_datetime('2050-01-01'), pd.to_datetime('2075-01-01'), pd.to_datetime('2100-01-01')])\n",
    "            #axs[s].set_xticks([pd.to_datetime('2025'), pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')])\n",
    "\n",
    "\n",
    "        # Setting y limits uniform within basins\n",
    "        if s == 0:\n",
    "            axs[s].set_ylabel(basinstext + r' $[km^3]$')\n",
    "        else:\n",
    "            axs[s].set_ylabel(None)\n",
    "            axs[s].set_yticklabels('')\n",
    "\n",
    "# Limits determined by max/min between all GCMs\n",
    "row_min = np.inf\n",
    "row_max = -np.inf\n",
    "for s in range(len(scenarios)):\n",
    "    data_min = np.min(axs[s].get_ybound()[0])\n",
    "    data_max = np.max(axs[s].get_ybound()[1])\n",
    "    if data_min < row_min:\n",
    "        row_min = data_min\n",
    "    if data_max > row_max:\n",
    "        row_max = data_max\n",
    "\n",
    "for s in range(len(scenarios)):\n",
    "    axs[s].set_ylim(row_min, row_max)\n",
    "\n",
    "# Legend\n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM')\n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "#axs[0].legend(handles=[green_patch, purple_patch, blue_patch], bbox_to_anchor=(3.15, 1.2), ncol=3)\n",
    "\n",
    "# Titles\n",
    "#plt.suptitle(f'{basin} Runoff Projections for Major Southern Andes River Basins', x=0.5, y=0.9)\n",
    "#plt.title('SSP 126                            SSP 245                           SSP 370                             SSP 585', x=-1.28, y=1)\n",
    "# Show the plot\n",
    "name = basinstext\n",
    "plt.savefig(f\"/Users/finnwimberly/Desktop/Lizz Research/AGU Figures/{name}.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920c0f1-5360-48ed-bfec-0690ca7b3a07",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e9bba-0fd1-4da0-9008-68c6123a261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating inter-GCM variance\n",
    "inter_GCM_variance = {}\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    inter_GCM_variance[gmodel] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        inter_GCM_variance[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins):\n",
    "            \n",
    "            if gmodel in gmodels_2regions and basin in basins_14:\n",
    "                GCM_dataframes = combined_1314_rf_data_annual[gmodel][SSP][basin]\n",
    "            \n",
    "            if gmodel in gmodels_2regions and basin in basins_15:\n",
    "                GCM_dataframes = combined_1315_rf_data_annual[gmodel][SSP][basin]\n",
    "            else:\n",
    "                GCM_dataframes = all_rf_data_annual[gmodel][SSP][basin]\n",
    "                \n",
    "            combined_dfs = pd.concat(GCM_dataframes, axis =1)\n",
    "            inter_GCM_variance[gmodel][SSP][basin] = combined_dfs.var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e619b-abe1-40e3-879d-6c03c7ce11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(basins), len(scenarios), figsize=(10, 2.4*len(basins)), sharex=True)\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        for b, basin in enumerate(basins):\n",
    "            axs[b,s].plot(yrs_dt, inter_GCM_variance[gmodel][SSP][basin].rolling(window=15).mean(), color=colors[g], label = gmodel)            \n",
    "                \n",
    "            if b == (len(basins)-1):\n",
    "                for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                    axs[b, sub_s].set_xlabel('Year')\n",
    "                    axs[b, sub_s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "            if s == 0:                                                                    #Setting basin labels\n",
    "                for sub_b in range(len(basins)):\n",
    "                    axs[sub_b,s].set_ylabel(basinstext[sub_b]+ r'  $\\sigma^2$')\n",
    "            if s != 0:\n",
    "                axs[b, s].set_ylabel(None)\n",
    "                axs[b, s].set_yticklabels('')\n",
    "\n",
    "for b in range(len(basins)):         #Limits determined by max/min between all GCMs\n",
    "    row_min = np.inf\n",
    "    row_max = -np.inf\n",
    "    for s in range(len(scenarios)):\n",
    "        data_min = np.min(axs[b, s].get_ybound()[0])\n",
    "        data_max = np.max(axs[b, s].get_ybound()[1])\n",
    "        if data_min < row_min:\n",
    "            row_min = data_min\n",
    "        if data_max > row_max:\n",
    "            row_max = data_max\n",
    "    for s in range(len(scenarios)):\n",
    "        axs[b, s].set_ylim(row_min/1.5, row_max*1.2)\n",
    "        \n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "\n",
    "axs[0,0].legend(handles=[green_patch, purple_patch, blue_patch], bbox_to_anchor=(3.15, (0.115*len(basins))), ncol=3)\n",
    "plt.suptitle('Inter-GCM Variance in Runoff Projections for Southern Asian River Basins', x=0.5, y=0.905)\n",
    "plt.title('SSP 126                          SSP 245                         SSP 370                          SSP 585', x=-1.3, y=(1.182* len(basins))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ebdd4-f7b6-4c1d-906c-ac0f0e53c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating inter-annual variance\n",
    "rolling_years = 15\n",
    "\n",
    "interannual_variance = {}\n",
    "interannual_variance_mean = {}\n",
    "\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    interannual_variance[gmodel] = {}\n",
    "    interannual_variance_mean[gmodel] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        interannual_variance[gmodel][SSP] = {}\n",
    "        interannual_variance_mean[gmodel][SSP] = {}\n",
    "        for b, basin in enumerate(basins):\n",
    "            interannual_variance[gmodel][SSP][basin] = {}\n",
    "\n",
    "            if gmodel in gmodels_2regions and basin in basins_14:\n",
    "                GCM_dataframes = combined_1314_rf_data_annual[gmodel][SSP][basin]\n",
    "            \n",
    "            if gmodel in gmodels_2regions and basin in basins_15:\n",
    "                GCM_dataframes = combined_1315_rf_data_annual[gmodel][SSP][basin]\n",
    "        \n",
    "            else:\n",
    "                data = all_rf_data_annual[gmodel][SSP][basin]\n",
    "            combined_dfs = pd.concat(data, axis =1)\n",
    "            \n",
    "            if gmodel == 'OGGM':\n",
    "                for m, GCM in enumerate(modelnames_all):\n",
    "                    interannual_variance[gmodel][SSP][basin][GCM] = data[GCM][0:-1].rolling(window=rolling_years, min_periods=10, center = True).var()\n",
    "                interannual_variance_mean[gmodel][SSP][basin] = combined_dfs[0:-1].rolling(window=rolling_years, min_periods=10, center = True).var().mean(axis=1)\n",
    "\n",
    "            else:\n",
    "                for m, GCM in enumerate(modelnames_all):\n",
    "                    interannual_variance[gmodel][SSP][basin][GCM] = data[GCM].rolling(window=rolling_years, min_periods=10, center = True).var()\n",
    "                interannual_variance_mean[gmodel][SSP][basin] = combined_dfs.rolling(window=rolling_years, min_periods=10, center = True).var().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb44782-f508-428c-802e-9015d1b94aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(basins), len(scenarios), figsize=(10, 2.4*len(basins)), sharex=True)\n",
    "for g, gmodel in enumerate(glacier_models):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        for b, basin in enumerate(basins):\n",
    "            if gmodel == 'OGGM':\n",
    "                axs[b,s].plot(yrs_dt[0:-1], interannual_variance_mean[gmodel][SSP][basin], color=colors[g], label = gmodel)\n",
    "                for m, GCM in enumerate(modelnames_all):   \n",
    "                    axs[b,s].plot(yrs_dt[0:-1], interannual_variance[gmodel][SSP][basin][GCM], color=axs[b, s].set_prop_cycle(colorschemes[gmodel]), label = gmodel, alpha = 0.25)            \n",
    "            else:\n",
    "                axs[b,s].plot(yrs_dt, interannual_variance_mean[gmodel][SSP][basin], color=colors[g], label = gmodel)\n",
    "                for m, GCM in enumerate(modelnames_all):   \n",
    "                    axs[b,s].plot(yrs_dt, interannual_variance[gmodel][SSP][basin][GCM], color=axs[b, s].set_prop_cycle(colorschemes[gmodel]), label = gmodel, alpha = 0.25)      \n",
    "                \n",
    "                if b == (len(basins)-1):\n",
    "                    for sub_s in range(4):  # Use a different variable name for the inner loop\n",
    "                        axs[b, sub_s].set_xlabel('Year')\n",
    "                        axs[b, sub_s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "                if s == 0:                                                                    #Setting basin labels\n",
    "                    for sub_b in range(len(basins)):\n",
    "                        axs[sub_b,s].set_ylabel(basinstext[sub_b]+ r'  $\\sigma^2$')\n",
    "                if s != 0:\n",
    "                    axs[b, s].set_ylabel(None)\n",
    "                    axs[b, s].set_yticklabels('')\n",
    "\n",
    "for b in range(len(basins)):         #Limits determined by max/min between all GCMs\n",
    "    row_min = np.inf\n",
    "    row_max = -np.inf\n",
    "    for s in range(len(scenarios)):\n",
    "        data_min = np.min(axs[b, s].get_ybound()[0])\n",
    "        data_max = np.max(axs[b, s].get_ybound()[1])\n",
    "        if data_min < row_min:\n",
    "            row_min = data_min\n",
    "        if data_max > row_max:\n",
    "            row_max = data_max\n",
    "    for s in range(len(scenarios)):\n",
    "        axs[b, s].set_ylim(row_min, row_max)\n",
    "        \n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "\n",
    "axs[0,0].legend(handles=[green_patch, purple_patch, blue_patch], bbox_to_anchor=(3.15, (0.115*len(basins))), ncol=3)\n",
    "plt.suptitle('Inter-Annual Variance in Runoff Projections for Southern Asian River Basins', x=0.5, y=0.905)\n",
    "plt.title('SSP 126                          SSP 245                         SSP 370                          SSP 585', x=-1.3, y=(1.182* len(basins))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa685617-055f-4197-a628-36157f1f0c4d",
   "metadata": {},
   "source": [
    "#### Saving Variance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c5fbb-a846-402e-8495-7cff5fb6a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2101, 12, 1)\n",
    "indices = pd.date_range(start_date, end_date, freq='A').strftime('%Y-%m').tolist()\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        glo_values = inter_GCM_variance['GloGEM'][SSP][basin].values.flatten()\n",
    "        pygem_values = inter_GCM_variance['PyGEM'][SSP][basin].values.flatten()\n",
    "        oggm_values = inter_GCM_variance['OGGM'][SSP][basin].values.flatten()\n",
    "        \n",
    "        out_df[SSP][basin] = pd.DataFrame(\n",
    "            {\n",
    "                'GloGEM': glo_values,\n",
    "                'PyGEM': pygem_values,\n",
    "                'OGGM': oggm_values,\n",
    "            },\n",
    "            index=indices\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78f1f3-f197-4249-b9b4-20df2e7639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Variance/RGI 13/'\n",
    "\n",
    "for SSP in out_df:\n",
    "    for basin in out_df[SSP]:\n",
    "        for GCM in out_df[SSP][basin]:\n",
    "            fname = f\"interGCM_variance_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb7238-1d4a-4e02-ac9c-ffdde16d25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2101, 12, 1)\n",
    "indices = pd.date_range(start_date, end_date, freq='A').strftime('%Y-%m').tolist()\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            glo_values = interannual_variance['GloGEM'][SSP][basin][model].values.flatten()\n",
    "            pygem_values = interannual_variance['PyGEM'][SSP][basin][model].values.flatten()\n",
    "            oggm_values = interannual_variance['OGGM'][SSP][basin][model].values.flatten()\n",
    "            oggm_values = np.append(oggm_values, np.nan) \n",
    "            \n",
    "            out_df[SSP][basin][model] = pd.DataFrame(\n",
    "                {\n",
    "                    'GloGEM': glo_values,\n",
    "                    'PyGEM': pygem_values,\n",
    "                    'OGGM': oggm_values,\n",
    "                },\n",
    "                index=indices\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5aef9-fd6e-4f36-860b-f70b5fdce8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Variance/RGI 13/'\n",
    "\n",
    "for SSP in out_df:\n",
    "    for basin in out_df[SSP]:\n",
    "        for GCM in out_df[SSP][basin]:\n",
    "            fname = f\"interannual_variance_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba77b2-6432-464e-8496-37cecb862600",
   "metadata": {},
   "source": [
    "### Reading Out Monthly Runoff in a Single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b426ee7-9de9-4408-85b1-c0db81a69e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            if basin in basins_14:\n",
    "                glo_values = combined_1314_rf_data['GloGEM'][SSP][basin][model].values.flatten()\n",
    "                pygem_values = combined_1314_rf_data['PyGEM'][SSP][basin][model].values.flatten()\n",
    "                oggm_values = all_rf_data['OGGM'][SSP][basin][model].values.flatten()\n",
    "\n",
    "            if basin in basins_15:\n",
    "                glo_values = combined_1315_rf_data['GloGEM'][SSP][basin][model].values.flatten()\n",
    "                pygem_values = combined_1315_rf_data['PyGEM'][SSP][basin][model].values.flatten()\n",
    "                oggm_values = all_rf_data['OGGM'][SSP][basin][model].values.flatten()\n",
    "\n",
    "            if basin not in basins_14 and basin not in basins_15:\n",
    "                glo_values = all_rf_data['GloGEM'][SSP][basin][model].values.flatten()\n",
    "                pygem_values = all_rf_data['PyGEM'][SSP][basin][model].values.flatten()\n",
    "                oggm_values = all_rf_data['OGGM'][SSP][basin][model].values.flatten()\n",
    "                \n",
    "            out_df[SSP][basin][model] = pd.DataFrame(\n",
    "                {\n",
    "                    'GloGEM': glo_values,\n",
    "                    'PyGEM': pygem_values,\n",
    "                    'OGGM': oggm_values,\n",
    "                },\n",
    "                index=indices\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567947e-a13e-491e-9ec4-7da853c9b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Runoff/RGI 13/'\n",
    "\n",
    "for SSP in out_df:\n",
    "    for basin in out_df[SSP]:\n",
    "        for GCM in out_df[SSP][basin]:\n",
    "            fname = f\"runoff_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51fa2a-c0aa-4454-a0ed-e27e5bbf102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index for the expanded timeline\n",
    "start_date_glo = datetime.date(1999, 10, 1)  # GloGEM starts in October 1999\n",
    "end_date_glo = datetime.date(2100, 12, 1)   # GloGEM ends in December 2100\n",
    "new_indices = pd.date_range(start_date_glo, end_date_glo, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df2 = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df2[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df2[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            #Apply aligned indices\n",
    "            out_df2[SSP][basin][model] = out_df[SSP][basin][model].reindex(new_indices)\n",
    "            \n",
    "            #Shift GloGEM to proper starting point\n",
    "            column_to_shift = ['GloGEM']\n",
    "            shift_count = -3\n",
    "            out_df2[SSP][basin][model][column_to_shift] = out_df2[SSP][basin][model][column_to_shift].shift(shift_count, fill_value=0)\n",
    "\n",
    "            #Replace NaNs with zeros\n",
    "            out_df2[SSP][basin][model]['OGGM'][0:3] = 0\n",
    "            out_df2[SSP][basin][model]['PyGEM'][0:3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a71eea-aeb4-464c-9c79-02008defddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Runoff/RGI 13/'\n",
    "\n",
    "for SSP in out_df2:\n",
    "    for basin in out_df2[SSP]:\n",
    "        for GCM in out_df2[SSP][basin]:\n",
    "            fname = f\"runoff_AlignedMonthly_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df2[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8652a02-b781-4299-8d49-f78839518148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
