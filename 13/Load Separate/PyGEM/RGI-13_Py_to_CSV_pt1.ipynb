{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd36cf0-c2f3-46e8-b8fe-dde123da9258",
   "metadata": {},
   "source": [
    "### Aggregation of PyGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac681a9-ce08-4d24-8f4a-8c62fc648edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260484b9-f321-4838-91df-21d341f17ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the climate models used\n",
    "modelnames_py = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585'] #List of all SSPs in PyGEM\n",
    "\n",
    "Alpine_basins = {'YSYK-KOL':'2919', 'TARIM HE':'2914', 'TALAS':'2913', 'LAKE BALKHASH':'2910', \n",
    "    'CHUY':'2905','ARAL SEA':'2902', 'YELLOW RIVER':'2434', 'MEKONG':'2421', 'SALWEEN':'2319', \n",
    "    'INDUS':'2309', 'BRAHMAPUTRA':'2302', 'YANGTZE' : '2433'}\n",
    "\n",
    "basins = ['YSYK-KOL', 'TARIM HE', 'TALAS', 'LAKE BALKHASH', 'CHUY', 'ARAL SEA', 'YELLOW RIVER', 'MEKONG', \n",
    "          'SALWEEN', 'INDUS', 'BRAHMAPUTRA', 'YANGTZE']\n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathPy = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/Runoff-intercomparison/PyGEM/13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a490d18d-3851-4cdb-8e3e-200f092d9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ad6cd16-6629-4849-98b3-05731061c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "basin_gls_13 = {}   #Creating list that does not include glaciers in RGI 14 or 15\n",
    "for basin, code in Alpine_basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)\n",
    "    basin_gls_13[basin] = []\n",
    "    for g, glacier in enumerate(basin_gls[basin]):\n",
    "        if int(basin_gls[basin][g][6:8]) == 13:\n",
    "            basin_gls_13[basin].append(glacier)\n",
    "\n",
    "# basin_gls_13 = {}\n",
    "# for basin in basins:\n",
    "#     basin_gls_13[basin] = []\n",
    "#     for g, glacier in enumerate(basin_gls[basin]):\n",
    "#         if int(basin_gls[basin][g][6:8]) == 13:\n",
    "#             basin_gls_13[basin].append(glacier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66cb9c2-682b-49c7-a410-5e7672496b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, taking annual sum, and converting m^3 to km^3\n",
    "import glob   #use glob to group files by filename similarities (in this case, SSP)\n",
    "\n",
    "rf_ds = {}\n",
    "#annual_rf_ds = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    fpath1 = '/R13_runoff_monthly_c2_ba1_1set_2000_2100-{}'.format(SSP)\n",
    "    file_pattern = f'{fpathPy + fpath1}*.nc'\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    #print(file_list)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            with xr.open_dataset(file) as ds:\n",
    "                ds = ds.glac_runoff_monthly.load()\n",
    "                datasets.append(ds)\n",
    "    \n",
    "        combined_ds = xr.concat(datasets, dim='glacier')  # Concatenate the datasets\n",
    "        rf_ds[SSP] = combined_ds\n",
    "        #annual_rf_ds[SSP] = rf_ds[SSP].resample(time='A').sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779589f-2a83-4461-a29d-a78615b7e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to make 'Climate_Model' and 'RGIId' dimensions so that we can call by name not int\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    rf_ds[SSP] = rf_ds[SSP].set_index(model='Climate_Model', glacier='RGIId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4df49970-7e6c-47b9-a8ef-bebadc30f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RGI60-13.11762',\n",
       " 'RGI60-13.11763',\n",
       " 'RGI60-13.11765',\n",
       " 'RGI60-13.11766',\n",
       " 'RGI60-13.11770',\n",
       " 'RGI60-13.11811',\n",
       " 'RGI60-13.11814',\n",
       " 'RGI60-13.17003',\n",
       " 'RGI60-13.17005',\n",
       " 'RGI60-13.17006',\n",
       " 'RGI60-13.17007',\n",
       " 'RGI60-13.17008',\n",
       " 'RGI60-13.17009',\n",
       " 'RGI60-13.17010',\n",
       " 'RGI60-13.17011',\n",
       " 'RGI60-13.17012',\n",
       " 'RGI60-13.17017',\n",
       " 'RGI60-13.17018',\n",
       " 'RGI60-13.17025',\n",
       " 'RGI60-13.17028',\n",
       " 'RGI60-13.17030',\n",
       " 'RGI60-13.17031',\n",
       " 'RGI60-13.17032',\n",
       " 'RGI60-13.17033',\n",
       " 'RGI60-13.17036',\n",
       " 'RGI60-13.17037',\n",
       " 'RGI60-13.17038',\n",
       " 'RGI60-13.17041',\n",
       " 'RGI60-13.17043',\n",
       " 'RGI60-13.17044',\n",
       " 'RGI60-13.17045',\n",
       " 'RGI60-13.17046',\n",
       " 'RGI60-13.17047',\n",
       " 'RGI60-13.17048',\n",
       " 'RGI60-13.17049',\n",
       " 'RGI60-13.17050',\n",
       " 'RGI60-13.17051',\n",
       " 'RGI60-13.17088',\n",
       " 'RGI60-13.17089',\n",
       " 'RGI60-13.17090',\n",
       " 'RGI60-13.17091',\n",
       " 'RGI60-13.17117',\n",
       " 'RGI60-13.17118',\n",
       " 'RGI60-13.17119',\n",
       " 'RGI60-13.17120',\n",
       " 'RGI60-13.17122',\n",
       " 'RGI60-13.17129',\n",
       " 'RGI60-13.17130',\n",
       " 'RGI60-13.17131',\n",
       " 'RGI60-13.17132',\n",
       " 'RGI60-13.17133',\n",
       " 'RGI60-13.17134',\n",
       " 'RGI60-13.17135',\n",
       " 'RGI60-13.17136',\n",
       " 'RGI60-13.17137',\n",
       " 'RGI60-13.17138',\n",
       " 'RGI60-13.17139',\n",
       " 'RGI60-13.17140',\n",
       " 'RGI60-13.17157',\n",
       " 'RGI60-13.17158',\n",
       " 'RGI60-13.17159',\n",
       " 'RGI60-13.17160',\n",
       " 'RGI60-13.17161',\n",
       " 'RGI60-13.17162',\n",
       " 'RGI60-13.17164',\n",
       " 'RGI60-13.17165',\n",
       " 'RGI60-13.17167',\n",
       " 'RGI60-13.17168',\n",
       " 'RGI60-13.17169',\n",
       " 'RGI60-13.17170',\n",
       " 'RGI60-13.17171',\n",
       " 'RGI60-13.17172',\n",
       " 'RGI60-13.17173',\n",
       " 'RGI60-13.17174',\n",
       " 'RGI60-13.17196',\n",
       " 'RGI60-13.17203',\n",
       " 'RGI60-13.21778',\n",
       " 'RGI60-13.21779',\n",
       " 'RGI60-13.21780',\n",
       " 'RGI60-13.21781',\n",
       " 'RGI60-13.21782',\n",
       " 'RGI60-13.21783',\n",
       " 'RGI60-13.21784',\n",
       " 'RGI60-13.21785',\n",
       " 'RGI60-13.21786',\n",
       " 'RGI60-13.21787',\n",
       " 'RGI60-13.21788',\n",
       " 'RGI60-13.21789',\n",
       " 'RGI60-13.21790',\n",
       " 'RGI60-13.21855',\n",
       " 'RGI60-13.21858',\n",
       " 'RGI60-13.21873',\n",
       " 'RGI60-13.21875',\n",
       " 'RGI60-13.21877',\n",
       " 'RGI60-13.21878',\n",
       " 'RGI60-13.21879',\n",
       " 'RGI60-13.21880',\n",
       " 'RGI60-13.21881',\n",
       " 'RGI60-13.21882',\n",
       " 'RGI60-13.21883',\n",
       " 'RGI60-13.21884',\n",
       " 'RGI60-13.21885',\n",
       " 'RGI60-13.21886',\n",
       " 'RGI60-13.21887',\n",
       " 'RGI60-13.21888',\n",
       " 'RGI60-13.21889',\n",
       " 'RGI60-13.21896',\n",
       " 'RGI60-13.21897',\n",
       " 'RGI60-13.21898',\n",
       " 'RGI60-13.21899',\n",
       " 'RGI60-13.21900',\n",
       " 'RGI60-13.21902',\n",
       " 'RGI60-13.21903',\n",
       " 'RGI60-13.21904',\n",
       " 'RGI60-13.21905',\n",
       " 'RGI60-13.21925',\n",
       " 'RGI60-13.21926',\n",
       " 'RGI60-13.21927',\n",
       " 'RGI60-13.21928',\n",
       " 'RGI60-13.21929',\n",
       " 'RGI60-13.21930',\n",
       " 'RGI60-13.21931',\n",
       " 'RGI60-13.21932',\n",
       " 'RGI60-13.21938',\n",
       " 'RGI60-13.21939',\n",
       " 'RGI60-13.21940',\n",
       " 'RGI60-13.21941',\n",
       " 'RGI60-13.21943',\n",
       " 'RGI60-13.21944',\n",
       " 'RGI60-13.21945',\n",
       " 'RGI60-13.21966',\n",
       " 'RGI60-13.21967',\n",
       " 'RGI60-13.21968',\n",
       " 'RGI60-13.22008',\n",
       " 'RGI60-13.22009',\n",
       " 'RGI60-13.22014',\n",
       " 'RGI60-13.22107',\n",
       " 'RGI60-13.22108',\n",
       " 'RGI60-13.22109',\n",
       " 'RGI60-13.22110',\n",
       " 'RGI60-13.22111',\n",
       " 'RGI60-13.22112',\n",
       " 'RGI60-13.22113',\n",
       " 'RGI60-13.22114',\n",
       " 'RGI60-13.22115',\n",
       " 'RGI60-13.22116',\n",
       " 'RGI60-13.22117',\n",
       " 'RGI60-13.22118',\n",
       " 'RGI60-13.22119',\n",
       " 'RGI60-13.22120',\n",
       " 'RGI60-13.22121',\n",
       " 'RGI60-13.22122',\n",
       " 'RGI60-13.22123',\n",
       " 'RGI60-13.22124',\n",
       " 'RGI60-13.22125',\n",
       " 'RGI60-13.22126',\n",
       " 'RGI60-13.22128',\n",
       " 'RGI60-13.22129',\n",
       " 'RGI60-13.22130',\n",
       " 'RGI60-13.22132',\n",
       " 'RGI60-13.22133',\n",
       " 'RGI60-13.22168',\n",
       " 'RGI60-13.22171',\n",
       " 'RGI60-13.22172',\n",
       " 'RGI60-13.22173',\n",
       " 'RGI60-13.22174',\n",
       " 'RGI60-13.22181',\n",
       " 'RGI60-13.22183',\n",
       " 'RGI60-13.22185',\n",
       " 'RGI60-13.22186',\n",
       " 'RGI60-13.22187',\n",
       " 'RGI60-13.22188',\n",
       " 'RGI60-13.22189',\n",
       " 'RGI60-13.22229']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_gls_13['TALAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7baa3ce2-1754-4b2e-904b-d07641032ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"not all values found in index 'glacier'. Try setting the `method` keyword argument (example: method='nearest').\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RGI60-13.36870'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/xarray/core/indexes.py:486\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label_value)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RGI60-13.36870'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ssp \u001b[38;5;129;01min\u001b[39;00m SSPs:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m, modelname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modelnames_py):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Extract the runoff data for the current glacier, SSP, and model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m         glacier_runoff \u001b[38;5;241m=\u001b[39m rf_ds[ssp]\u001b[38;5;241m.\u001b[39msel(model \u001b[38;5;241m=\u001b[39m modelname, glacier \u001b[38;5;241m=\u001b[39m RGIID)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Convert the DataArray to a NumPy array and then to a list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         glacier_runoff_list \u001b[38;5;241m=\u001b[39m glacier_runoff\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/xarray/core/dataarray.py:1549\u001b[0m, in \u001b[0;36mDataArray.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msel\u001b[39m(\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m: T_DataArray,\n\u001b[1;32m   1441\u001b[0m     indexers: Mapping[Any, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs: Any,\n\u001b[1;32m   1446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_DataArray:\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new DataArray whose data is given by selecting index\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;124;03m    labels along the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   1449\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;124;03m    Dimensions without coordinates: points\u001b[39;00m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1549\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_temp_dataset()\u001b[38;5;241m.\u001b[39msel(\n\u001b[1;32m   1550\u001b[0m         indexers\u001b[38;5;241m=\u001b[39mindexers,\n\u001b[1;32m   1551\u001b[0m         drop\u001b[38;5;241m=\u001b[39mdrop,\n\u001b[1;32m   1552\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1553\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs,\n\u001b[1;32m   1555\u001b[0m     )\n\u001b[1;32m   1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/xarray/core/dataset.py:2642\u001b[0m, in \u001b[0;36mDataset.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m \u001b[38;5;124;03malong the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   2583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;124;03mDataArray.sel\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2641\u001b[0m indexers \u001b[38;5;241m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2642\u001b[0m query_results \u001b[38;5;241m=\u001b[39m map_index_queries(\n\u001b[1;32m   2643\u001b[0m     \u001b[38;5;28mself\u001b[39m, indexers\u001b[38;5;241m=\u001b[39mindexers, method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[1;32m   2644\u001b[0m )\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop:\n\u001b[1;32m   2647\u001b[0m     no_scalar_variables \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/xarray/core/indexing.py:190\u001b[0m, in \u001b[0;36mmap_index_queries\u001b[0;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(IndexSelResult(labels))\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(index\u001b[38;5;241m.\u001b[39msel(labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions))\n\u001b[1;32m    192\u001b[0m merged \u001b[38;5;241m=\u001b[39m merge_sel_results(results)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# drop dimension coordinates found in dimension indexers\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# (also drop multi-index if any)\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# (.sel() already ensures alignment)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ulteelab/lib/python3.11/site-packages/xarray/core/indexes.py:488\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label_value)\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 488\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot all values found in index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry setting the `method` keyword argument (example: method=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m label_array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    494\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m label_array\n",
      "\u001b[0;31mKeyError\u001b[0m: \"not all values found in index 'glacier'. Try setting the `method` keyword argument (example: method='nearest').\""
     ]
    }
   ],
   "source": [
    "glacier_data = []\n",
    "\n",
    "# Step 2: Iterate over each glacier and extract its runoff data for each SSP and each model\n",
    "for basin, RGIIDs in basin_gls_13.items():\n",
    "    for RGIID in RGIIDs:\n",
    "        for ssp in SSPs:\n",
    "            for m, modelname in enumerate(modelnames_py):\n",
    "                # Extract the runoff data for the current glacier, SSP, and model\n",
    "                glacier_runoff = rf_ds[ssp].sel(model = modelname, glacier = RGIID)\n",
    "                # Convert the DataArray to a NumPy array and then to a list\n",
    "                glacier_runoff_list = glacier_runoff.values.flatten().tolist()\n",
    "                # Append the data for the current glacier, SSP, and model to the list\n",
    "                glacier_data.append([glacier, ssp, model] + glacier_runoff_list)\n",
    "\n",
    "# Step 3: Create a DataFrame from the list of data\n",
    "out_df = pd.DataFrame(glacier_data, columns=['Glacier', 'SSP', 'Model'] + rf_ds['ssp126'].time.values.tolist())\n",
    "\n",
    "# Step 4: Write the DataFrame to a CSV file\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Load Separate/RGI 13/PyGEM/'\n",
    "\n",
    "fname = 'RGI13_Py_runoff_unsorted.csv'\n",
    "\n",
    "# Define the full path of the output file\n",
    "output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "out_df.to_csv(output_path, header=True, index=True)\n",
    "# csv_filename = 'glacier_runoff_data.csv'\n",
    "# df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283970e-3c3b-4643-b217-a519bc7c8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "#basin_datasets = {}\n",
    "basin_ds_monthly = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    #basin_datasets[basin] = {}\n",
    "    basin_ds_monthly[basin] = {}\n",
    "    for s, SSP in enumerate(SSPs):\n",
    "        #ds_list = []\n",
    "        ds_list_monthly = []\n",
    "        try:\n",
    "            #ds_filtered = annual_rf_ds[SSP].where(annual_rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            ds_filtered_monthly = rf_ds[SSP].where(rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            #ds_list.append(ds_filtered)\n",
    "            ds_list_monthly.append(ds_filtered_monthly)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        #basin_datasets[basin][SSP] = xr.concat(ds_list, dim='glacier')\n",
    "        basin_ds_monthly[basin][SSP] = xr.concat(ds_list_monthly, dim='glacier') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "972d59ce-863e-402a-8a56-2801c591211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping indexing (to match other models) and summing basins\n",
    "basin_sums_py = {}\n",
    "basin_sums_monthly_py = {}\n",
    "for s, SSP in enumerate(SSPs):        \n",
    "    basin_sums_py[SSP] = {}\n",
    "    basin_sums_monthly_py[SSP] = {}\n",
    "    for basin, glacier_list in basin_gls.items():\n",
    "        basin_sums_py[SSP][basin] = basin_datasets[basin][SSP].sum(dim='glacier')\n",
    "        basin_sums_monthly_py[SSP][basin] = basin_ds_monthly[basin][SSP].sum(dim='glacier')*1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ee1e5-ae1d-4c39-b7b6-16a87c6139b8",
   "metadata": {},
   "source": [
    "### CSV Readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a386ee-0cc0-49ae-9491-cdd56b88cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up filename to reflect what you're writing out, possibly in a nested loop\n",
    "modelnames_all = ['BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', \n",
    "                  'INM-CM4-8', 'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basins = ['TARIM HE', 'ARAL SEA', 'INDUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6e6cdc-04e1-4692-a50a-9e456f8524ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df_RGI14 = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df_RGI14[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df_RGI14[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            pygem_values = pd.DataFrame(basin_sums_monthly_py[SSP][basin].sel(model=m + 1)).values.flatten()\n",
    "\n",
    "            out_df_RGI14[SSP][basin][model] = pd.DataFrame(\n",
    "                {\n",
    "                    'PyGEM': pygem_values,\n",
    "                    \n",
    "                },\n",
    "                index=indices\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e258b96-71fb-434f-b76b-b720f589d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Yukon data\n",
    "output_dir_RGI13 = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Load Separate/RGI 13/PyGEM/'\n",
    "\n",
    "for SSP in out_df_RGI14:\n",
    "    for basin in out_df_RGI14[SSP]:\n",
    "        for GCM in out_df_RGI14[SSP][basin]:\n",
    "            fnameRGI14 = f\"runoff_fromRGI14_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_pathRGI14 = os.path.join(output_dir_RGI13, fnameRGI14)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df_RGI14[SSP][basin][GCM].to_csv(output_pathRGI14, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd40a43-387f-4918-81ff-9db597515696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
