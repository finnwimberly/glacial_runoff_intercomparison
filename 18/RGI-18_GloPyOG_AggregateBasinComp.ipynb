{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a60925c-6bb8-4e62-86b9-39fc29ee391f",
   "metadata": {},
   "source": [
    "## Comparison of GloGEM, PyGEM, and OGGM RGI 16 Runoff Outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4f74b-0fbe-4011-9fc7-01307c850179",
   "metadata": {},
   "source": [
    "This notebook imports and processes GloGEM, PyGEM, and OGGM RGI-01 outputs. Summing glacial runoff by basin, we produce a plot that compares the three models' projected runoff values for each basin by SSP. \n",
    "\n",
    "Last Updated: 7 July 2023 | FFW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f0f48-29d2-4ca3-973d-41ffec199f6b",
   "metadata": {},
   "source": [
    "### Aggregation of GloGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447710ec-e148-4db4-b6e6-e512f97df7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "## Generic the filepath to the main data folder\n",
    "fpath0 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/Runoff-intercomparison/GloGEM-output/RGI18-NewZealand/files/'  \n",
    "\n",
    "#All of the climate models used\n",
    "modelnames = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPpaths = ['ssp126','ssp245','ssp370','ssp585']   #Specifiying the SSP\n",
    "#SSPs = ['ssp119','ssp126','ssp245','ssp370','ssp585'] #Use a different path as we have all 5 ssps for volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d81f4-7be9-44b5-aa12-abbda4d1579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_discharges = [[] for _ in SSPpaths]\n",
    "\n",
    "for s, SSPpath in enumerate(SSPpaths):\n",
    "    model_discharges = []\n",
    "    for modelname in modelnames:\n",
    "        temp_df = pd.read_csv(fpath0 + modelname + '/' + SSPpaths[s]  + '/' + 'newzealand_Discharge_r1.dat', sep='\\s+', header=None, skiprows=1, index_col=0)\n",
    "        model_discharges.append(temp_df)\n",
    "    all_discharges[s] = model_discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8e918-8500-4ce9-9662-ac3c8a4621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_areas = [[] for _ in SSPpaths]\n",
    "\n",
    "for s, SSPpath in enumerate(SSPpaths):\n",
    "    model_areas = []\n",
    "    for modelname in modelnames:\n",
    "        temp_df = pd.read_csv(fpath0 + modelname  + '/' + SSPpaths[s]  + '/' + 'newzealand_Area_r1.dat', sep='\\s+', index_col=\"ID\")\n",
    "        model_areas.append(temp_df)\n",
    "    all_areas[s] = model_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59501679-4918-4858-9dad-cc0be8898af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(1980, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "new_indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Apply new index and datetime conversion\n",
    "for s, SSPpath_discharges in enumerate(all_discharges):\n",
    "    for m, discharge_df in enumerate(SSPpath_discharges):\n",
    "        all_discharges[s][m].columns = new_indices\n",
    "        all_discharges[s][m].columns = pd.to_datetime(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c587b-aa66-4978-8a43-0d7e76ff0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanding area dataset to match year-month dimension\n",
    "for s in range(len(SSPpaths)):\n",
    "    for i in range(len(all_areas[s])):\n",
    "        all_areas[s][i] = all_areas[s][i][all_areas[s][i].columns.repeat(12)]\n",
    "        \n",
    "for s, areas in enumerate(all_areas):\n",
    "    for i, area in enumerate(areas):\n",
    "        all_areas[s][i].columns = new_indices\n",
    "        all_areas[s][i].columns = pd.to_datetime(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808a2ca-4424-4663-b244-b1542a2fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use our initial area to compute runoff so we fill entire dfs with element 0\n",
    "# We only use one SSP because the initial areas are all the same -- we save time without looping through all\n",
    "# We also convert km^2 to m^2\n",
    "\n",
    "initial_areas = [pd.DataFrame(df.iloc[:, 0].values.repeat(df.shape[1]).reshape(df.shape), index=df.index, columns=df.columns).mul(1e6) for df in all_areas[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99012fa0-eaa5-4b33-8f8e-d2aef78f3be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff = {s: {m: None for m in modelnames} for s in SSPpaths} # create nested dictionary indexed by model name and ssp\n",
    "n=0\n",
    "for s in SSPpaths:\n",
    "    i=0\n",
    "    for m in modelnames:\n",
    "        runoff[s][m] = pd.concat([initial_areas[i] * all_discharges[n][i]], axis=1)\n",
    "        i+=1\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33427b-d2a0-4aa4-bef0-0203bb6a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "annualrunoff = {s: {m: None for m in modelnames} for s in SSPpaths}\n",
    "for s, m in itertools.product(SSPpaths, modelnames):\n",
    "    annualrunoff[s][m] = runoff[s][m].transpose().resample('A').sum() * 1e-9  #m^3 to km^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f8e8-e4c4-48fd-a398-0b99132887d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3cdbe-be9c-4eec-b79a-197f1043fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_basin(basin_RGI_list, runoff_data):\n",
    "    # Create new list to match our RGI formatting\n",
    "    new_basin_list = [int(str(x)[-4:]) for x in basin_RGI_list]\n",
    "    runoff_data = runoff_data.transpose()\n",
    "    \n",
    "    #TODO: create list of glaciers within a basin that are not included in GloGEM output\n",
    "    # Filter new_basin_list to keep only the indexes present in the DataFrame\n",
    "    new_basin_list = [x for x in new_basin_list if x in runoff_data.index]\n",
    "    \n",
    "    # Extract glaciers contained in the list from original df and create a new df\n",
    "    new_df = runoff_data.loc[new_basin_list].copy()\n",
    "    \n",
    "    # Sum the values of the glaciers within the basin\n",
    "    summed_basin_runoff = new_df.sum()\n",
    "    #print(summed_basin_runoff)\n",
    "    \n",
    "    return summed_basin_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d068dc6-230d-4a10-9695-f09575334d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the aggregated basin data\n",
    "Alpine_basins = {'CLUTHA':'5406'}\n",
    "\n",
    "basins = ['CLUTHA']\n",
    "\n",
    "modelnames_glo = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basin_sums_glo = {}\n",
    "basin_sums_monthly_glo = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    basin_sums_glo[SSP] = {}\n",
    "    basin_sums_monthly_glo[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        basin_sums_glo[SSP][basin] = {}\n",
    "        basin_sums_monthly_glo[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_glo):\n",
    "            basin_sums_glo[SSP][basin][model] = sum_basin(select_glaciers_json(Alpine_basins[basin]), annualrunoff[SSP][model]) \n",
    "            basin_sums_monthly_glo[SSP][basin][model] = sum_basin(select_glaciers_json(Alpine_basins[basin]), runoff[SSP][model].transpose()*1e-9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b2bc7-3e32-41c9-bf25-1253fe671ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate multi GCM means and Quartiles we convert to df then calculate across first axis (GCMs)\n",
    "GCM_mean_glo = {}\n",
    "GCM_q1_glo = {}\n",
    "GCM_q3_glo = {}\n",
    "for s, SSP in enumerate(SSPpaths):\n",
    "    GCM_mean_glo[SSP] = {}\n",
    "    GCM_q1_glo[SSP] = {}\n",
    "    GCM_q3_glo[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        GCM_mean_glo[SSP][basin] = pd.DataFrame(basin_sums_glo[SSP][basin]).mean(axis=1)\n",
    "        GCM_q1_glo[SSP][basin] = pd.DataFrame(basin_sums_glo[SSP][basin]).quantile(q=0.25, axis=1)\n",
    "        GCM_q3_glo[SSP][basin] = pd.DataFrame(basin_sums_glo[SSP][basin]).quantile(q=0.75, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18fad1-a883-4176-bc06-2b7cba464834",
   "metadata": {},
   "source": [
    "### Aggregation of PyGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159b67d-0ca2-4c15-9f57-913d2b298cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "#All of the climate models used\n",
    "modelnames_py = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585'] #List of all SSPs in PyGEM\n",
    "\n",
    "Alpine_basins = {'CLUTHA':'5406'}\n",
    "\n",
    "basins = ['CLUTHA']\n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathPy = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/Runoff-intercomparison/PyGEM/18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a75458-1534-4c44-9a6b-59170bcf8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "for basin, code in Alpine_basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac464ff0-4830-4986-b389-51cdb216ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, taking annual sum, and converting m^3 to km^3\n",
    "import glob   #use glob to group files by filename similarities (in this case, SSP)\n",
    "\n",
    "rf_ds = {}\n",
    "annual_rf_ds = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    fpath1 = '/R18_runoff_monthly_c2_ba1_1set_2000_2100-{}'.format(SSP)\n",
    "    file_pattern = f'{fpathPy + fpath1}*.nc'\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    #print(file_list)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            with xr.open_dataset(file) as ds:\n",
    "                ds = ds.glac_runoff_monthly.load()\n",
    "                datasets.append(ds)\n",
    "    \n",
    "        combined_ds = xr.concat(datasets, dim='glacier')  # Concatenate the datasets\n",
    "        rf_ds[SSP] = combined_ds\n",
    "        annual_rf_ds[SSP] = rf_ds[SSP].resample(time='A').sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce4835-b9a0-4b4a-96de-f4f9b4c8c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "basin_datasets = {}\n",
    "basin_ds_monthly = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    basin_datasets[basin] = {}\n",
    "    basin_ds_monthly[basin] = {}\n",
    "    for s, SSP in enumerate(SSPs):\n",
    "        ds_list = []\n",
    "        ds_list_monthly = []\n",
    "        try:\n",
    "            ds_filtered = annual_rf_ds[SSP].where(annual_rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            ds_filtered_monthly = rf_ds[SSP].where(rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            ds_list.append(ds_filtered)\n",
    "            ds_list_monthly.append(ds_filtered_monthly)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        basin_datasets[basin][SSP] = xr.concat(ds_list, dim='glacier')\n",
    "        basin_ds_monthly[basin][SSP] = xr.concat(ds_list_monthly, dim='glacier') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc05b0e-ad06-448a-b1fc-63c124f33ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping indexing (to match other models) and summing basins\n",
    "basin_sums_py = {}\n",
    "basin_sums_monthly_py = {}\n",
    "for s, SSP in enumerate(SSPs):        \n",
    "    basin_sums_py[SSP] = {}\n",
    "    basin_sums_monthly_py[SSP] = {}\n",
    "    for basin, glacier_list in basin_gls.items():\n",
    "        basin_sums_py[SSP][basin] = basin_datasets[basin][SSP].sum(dim='glacier')\n",
    "        basin_sums_monthly_py[SSP][basin] = basin_ds_monthly[basin][SSP].sum(dim='glacier')*1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff53b4-c886-4825-844b-6600eabcfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute multi GCM means and quartiles\n",
    "GCM_mean_py = {}\n",
    "GCM_q1_py = {}\n",
    "GCM_q3_py = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    GCM_mean_py[SSP] = {}\n",
    "    GCM_q1_py[SSP] = {}\n",
    "    GCM_q3_py[SSP] = {}\n",
    "    for basin in basins:\n",
    "        GCM_mean_py[SSP][basin] = basin_sums_py[SSP][basin].mean(dim = 'model')\n",
    "        GCM_q1_py[SSP][basin] = basin_sums_py[SSP][basin].quantile(q = 0.25, dim = 'model')\n",
    "        GCM_q3_py[SSP][basin] = basin_sums_py[SSP][basin].quantile(q = 0.75, dim = 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915200b-374f-404b-a9d0-fda9b8e74490",
   "metadata": {},
   "source": [
    "### Aggregation of OGGM Runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888f950-d37b-4d39-9fb7-dc895d6fd576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the climate models used\n",
    "modelnames_OG = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CESM2', 'CESM2-WACCM', 'CMCC-CM2-SR5','EC-Earth3', \n",
    "                'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', 'INM-CM4-8','INM-CM5-0', \n",
    "                 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM', 'TaiESM1']\n",
    "\n",
    "Alpine_basins = {'CLUTHA':'5406'}\n",
    "\n",
    "basins = ['CLUTHA']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "# CMCC-CM2-SR5 & TaiESM1 only hold values for ssp585––this is model list without those GCMS\n",
    "modelnames_OG_trimmed = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', \n",
    "                         'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', 'INM-CM4-8',\n",
    "                           'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathOG1 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/'\n",
    "fpathOG2 = 'Lizz Research Stuff/Runoff-intercomparison/OGGM/lschuster/runs_2023.3/output/basins/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb82c9-ae36-4d8e-90fa-322ffa5544a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, OGGM is grouped by basin\n",
    "rf_ds = {}\n",
    "rf_ds_monthly = {}\n",
    "for basin, ID in Alpine_basins.items():\n",
    "    fpath_basin = 'gcm_from_2000_bc_2000_2019/{}/'.format(ID)\n",
    "    #print(f'{fpathOG1 + fpathOG2 + fpath_basin}*.nc')\n",
    "    with xr.open_mfdataset(f'{fpathOG1 + fpathOG2 + fpath_basin}*.nc') as ds1:\n",
    "        ds1 = ds1.runoff.load()\n",
    "    rf_ds[basin] = ds1\n",
    "    with xr.open_mfdataset(f'{fpathOG1 + fpathOG2 + fpath_basin}*.nc') as ds2:\n",
    "        ds_monthly = ds2.runoff_monthly.load()\n",
    "    rf_ds_monthly[basin] = ds_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb7ff6-4d1d-4058-98af-92ab7b85e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing individual glacier runoff into basin totals and converting kg to km^3\n",
    "basin_rf_OG = {}\n",
    "basin_rf_monthly_OG = {}\n",
    "for basin, ID in Alpine_basins.items():\n",
    "    basin_rf_OG[basin] = rf_ds[basin].sum(dim = 'rgi_id') * 1e-12\n",
    "    basin_rf_monthly_OG[basin] = rf_ds_monthly[basin].sum(dim = 'rgi_id') * 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf56a4-a51b-4d33-8fde-d6ead6af7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dict of GloPy format\n",
    "basin_sums_OG = {}\n",
    "basin_sums_monthly_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    basin_sums_OG[SSP] = {}\n",
    "    basin_sums_monthly_OG[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        basin_sums_OG[SSP][basin] = basin_rf_OG[basin].sel(scenario = SSP)\n",
    "        basin_sums_monthly_OG[SSP][basin] = basin_rf_monthly_OG[basin].sel(scenario = SSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901a217-eace-442e-8a9d-8d425221340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing these GCMs for ALL SSPs--doing even 585 as these two are not included...\n",
    "#... in Glo or Py so not only makeds OOGM easier but maintains GCM consistency in analysis\n",
    "trimmed_basin_sums_OG = {}\n",
    "trimmed_basin_sums_monthly_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    trimmed_basin_sums_OG[SSP] = {}\n",
    "    trimmed_basin_sums_monthly_OG[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        trimmed_basin_sums_OG[SSP][basin] = xr.concat([basin_sums_OG[SSP][basin][0:4], basin_sums_OG[SSP][basin][5:-1]], dim='gcm')\n",
    "        trimmed_basin_sums_monthly_OG[SSP][basin] = xr.concat([basin_sums_monthly_OG[SSP][basin][0:4], basin_sums_monthly_OG[SSP][basin][5:-1]], dim='gcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a83c1e-ef6d-48c6-848a-e5f5f6717313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute multi GCM means and quartiles for OGGM\n",
    "GCM_mean_OG = {}\n",
    "GCM_q1_OG = {}\n",
    "GCM_q3_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    which_ssp = SSPs[s]\n",
    "    GCM_mean_OG[which_ssp] = {}\n",
    "    GCM_q1_OG[which_ssp] = {}\n",
    "    GCM_q3_OG[which_ssp] = {}\n",
    "    for basin in basins:\n",
    "        GCM_mean_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].mean(dim = 'gcm')\n",
    "        GCM_q1_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].quantile(q = 0.25, dim = 'gcm')\n",
    "        GCM_q3_OG[which_ssp][basin] = trimmed_basin_sums_OG[which_ssp][basin].quantile(q = 0.75, dim = 'gcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc97b9-9121-4a89-a36d-719908779fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot setup\n",
    "from cycler import cycler\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "Alpine_basins = {'CLUTHA':'5406'}\n",
    "\n",
    "basins = ['CLUTHA']\n",
    "\n",
    "yrs_glo = np.arange(1980,2101)\n",
    "yrs_glo_dt = pd.to_datetime([str(y)for y in yrs_glo])\n",
    "\n",
    "colors_glo =  plt.colormaps['Greens']\n",
    "line_colors_glo = colors_glo(np.linspace(0.2, 0.6, num = 12))\n",
    "glo_cycler = cycler(color = line_colors_glo)\n",
    "\n",
    "colors_py =  plt.colormaps['Purples']\n",
    "line_colors_py = colors_py(np.linspace(0.2, 0.6,num = 12))\n",
    "py_cycler = cycler(color = line_colors_py)\n",
    "\n",
    "colors_OG =  plt.colormaps['Blues']\n",
    "line_colors_OG = colors_OG(np.linspace(0.2, 0.6,num = 12))\n",
    "OG_cycler = cycler(color = line_colors_OG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a4969-1292-44d8-ae0b-1f28cfbd54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(SSPs), figsize=(10, 2), sharex=True)\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basin = 'CLUTHA'\n",
    "basintext = 'Clutha'\n",
    "\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    #OG won't plot with built-in ds.plot()\n",
    "    #Trim last value as it goes to zero\n",
    "    for m, model in enumerate(modelnames_OG_trimmed):\n",
    "        axs[s].plot(yrs_glo_dt[20:-1], trimmed_basin_sums_OG[SSP][basin][:,0:-1].sel(gcm = modelnames_OG_trimmed[m]), color = 'dodgerblue', alpha = 0.15)\n",
    "    axs[s].plot(yrs_glo_dt[20:-1], GCM_mean_OG[SSP][basin][0:-1], color = 'royalblue', linewidth = 0.9, label = 'OGGM')\n",
    "    axs[s].plot(yrs_glo_dt[20:-1], GCM_q1_OG[SSP][basin][0:-1], color = 'royalblue', linewidth = 0.4)\n",
    "    axs[s].plot(yrs_glo_dt[20:-1], GCM_q3_OG[SSP][basin][0:-1], color = 'royalblue', linewidth = 0.4)\n",
    "    axs[s].fill_between(yrs_glo_dt[20:-1], GCM_q1_OG[SSP][basin][0:-1], GCM_q3_OG[SSP][basin][0:-1], color = 'dodgerblue', alpha = 0.5)\n",
    "\n",
    "    for m in modelnames_glo:\n",
    "        axs[s].plot(yrs_glo_dt, basin_sums_glo[SSP][basin][m], color=axs[s].set_prop_cycle(glo_cycler), alpha = 0.25)\n",
    "    axs[s].plot(yrs_glo_dt, GCM_mean_glo[SSP][basin], color = 'darkgreen', linewidth = 0.9, label = 'GloGEM')\n",
    "    axs[s].plot(yrs_glo_dt, GCM_q1_glo[SSP][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "    axs[s].plot(yrs_glo_dt, GCM_q3_glo[SSP][basin], color = 'darkgreen', linewidth = 0.4)\n",
    "    axs[s].fill_between(yrs_glo_dt, GCM_q1_glo[SSP][basin], GCM_q3_glo[SSP][basin], color = 'green')\n",
    "    axs[s].set(xlim=(pd.to_datetime('2000-01-01'), pd.to_datetime('2100-01-01')))\n",
    "\n",
    "    basin_sums_py[SSP][basin].plot(hue='model', ax=axs[s], color=axs[s].set_prop_cycle(py_cycler), alpha = 0.25, add_legend=False)\n",
    "    GCM_mean_py[SSP][basin].plot(hue='model', ax=axs[s], color = 'purple', linewidth = 0.9, add_legend=False, label = 'PyGEM')\n",
    "    GCM_q1_py[SSP][basin].plot(hue='model', ax=axs[s], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "    GCM_q3_py[SSP][basin].plot(hue='model', ax=axs[s], color = 'purple', linewidth = 0.4, add_legend=False)\n",
    "    axs[s].fill_between(yrs_glo_dt[20::], GCM_q1_py[SSP][basin], GCM_q3_py[which_ssp][basin], color = 'Purple')\n",
    "    axs[s].set(title = '')\n",
    "\n",
    "    for s in range(4):  # Use a different variable name for the inner loop\n",
    "        axs[s].set_xlabel('Year')\n",
    "        axs[s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "        if s == 0:                                                                    #Setting basin labels\n",
    "            axs[s].set_ylabel(r'Runoff  $[km^3]$')\n",
    "        if s != 0:\n",
    "            axs[s].set_ylabel('')\n",
    "            axs[s].set_yticklabels('')\n",
    "\n",
    "axs[0].legend(bbox_to_anchor=(3.15, 1.48), ncol=3)\n",
    "plt.suptitle('Projected Runoff for the '+str(basintext)+' River Basin', x=0.488, y=1.36)\n",
    "plt.title('SSP 126                          SSP 245                         SSP 370                          SSP 585', x=-1.3, y=1.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455e612-20d2-47c6-b535-65a673a86198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating inter-GCM variance\n",
    "variance_glo = {}\n",
    "variance_py = {}\n",
    "variance_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    variance_glo[SSP] = {}\n",
    "    variance_py[SSP] = {}\n",
    "    variance_OG[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        variance_glo[SSP][basin] = pd.DataFrame(basin_sums_glo[SSP][basin]).var(axis=1)\n",
    "        variance_py[SSP][basin] = basin_sums_py[SSP][basin].var(dim = 'model')\n",
    "        variance_OG[SSP][basin] =  trimmed_basin_sums_OG[SSP][basin].var(dim = 'gcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509975b-cdad-41b5-87ee-2e5c23034064",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(SSPs), figsize=(10, 2), sharex=True)\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basin = 'CLUTHA'\n",
    "basintext = 'Clutha'\n",
    "\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    axs[s].plot(yrs_dt, variance_glo[SSP][basin][20::], color='darkgreen')\n",
    "\n",
    "    axs[s].plot(yrs_dt, variance_OG[SSP][basin], color = 'dodgerblue')        \n",
    "\n",
    "    variance_py[SSP][basin].plot(hue='model', ax=axs[s], color= 'purple')\n",
    "        \n",
    "for s in range(4):  \n",
    "    axs[s].set_xlabel('Year')\n",
    "    axs[s].set_xlabel('')\n",
    "    axs[s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "    if s == 0:                                                                    #Setting basin labels\n",
    "        axs[s].set_ylabel(r'  $\\sigma^2$')\n",
    "    if s != 0:\n",
    "        axs[s].set_ylabel('')\n",
    "        axs[s].set_yticklabels('')\n",
    "    \n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "axs[0].legend(handles=[green_patch, purple_patch, blue_patch],bbox_to_anchor=(3.15, 1.4), ncol=3)\n",
    "plt.suptitle('Inter-Annual Variance for Projected Runoff of the '+str(basintext)+' River Basin', x=0.488, y=1.28)\n",
    "plt.title('SSP 126                          SSP 245                         SSP 370                          SSP 585', x=-1.3, y=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dfac1-8bcb-458a-8a96-8539d61ff5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating interannual variance\n",
    "rolling_years = 15\n",
    "yrs = np.arange(2000,2101)\n",
    "yrs_dt = pd.to_datetime([str(y)for y in yrs])\n",
    "\n",
    "annual_variance_glo = {}\n",
    "annual_variance_py = {}\n",
    "annual_variance_OG = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    annual_variance_glo[SSP] = {}\n",
    "    annual_variance_py[SSP] = {}\n",
    "    annual_variance_OG[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        #annual_variance_glo[SSP][basin] = pd.DataFrame(basin_sums_glo[SSP][basin]).rolling(window= rolling_years, min_periods=10, center = True).var(axis=0)\n",
    "        annual_variance_py[SSP][basin] = basin_sums_py[SSP][basin].rolling(time=rolling_years, min_periods=10, center = True).var()\n",
    "        annual_variance_OG[SSP][basin] =  trimmed_basin_sums_OG[SSP][basin][0::,0:-1].rolling(time=rolling_years, min_periods=10, center = True).var()\n",
    "        annual_variance_glo[SSP][basin] = {}\n",
    "        for m in modelnames_glo:\n",
    "            annual_variance_glo[SSP][basin][m]= pd.DataFrame(basin_sums_glo[which_ssp][basin][m]).rolling(window=rolling_years, min_periods=10, center = True).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ec854-996d-4777-92ab-e15f5fbe0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_variance_glo = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    mean_variance_glo[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        mean_variance_glo[SSP][basin] = GCM_mean_glo[SSP][basin].rolling(window=rolling_years, min_periods=10, center = True).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4e34e-99e6-4fa0-98e6-dfc0825bdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(SSPs), figsize=(10, 2), sharex=True)\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basin = 'CLUTHA'\n",
    "basintext = 'Clutha'\n",
    "\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    for m in modelnames_glo:               #Plotting Rf inter-annual Variance\n",
    "        axs[s].plot(yrs_dt, annual_variance_glo[SSP][basin][m][20::], color=axs[s].set_prop_cycle(glo_cycler), alpha = 0.25)\n",
    "        \n",
    "    for m, model in enumerate(modelnames_OG_trimmed):\n",
    "        axs[s].plot(yrs_dt[0:-1], annual_variance_OG[SSP][basin].sel(gcm = modelnames_OG_trimmed[m]), color = 'dodgerblue', alpha = 0.15)        \n",
    "\n",
    "        annual_variance_py[SSP][basin].plot(hue='model', ax=axs[s], color=axs[s].set_prop_cycle(py_cycler), alpha = 0.55, add_legend=False)\n",
    "        \n",
    "        axs[s].plot(yrs_dt, annual_variance_py[SSP][basin].mean(dim = 'model'), color = 'purple', label = 'PyGEM')\n",
    "        axs[s].plot(yrs_dt, mean_variance_glo[SSP][basin][20::], color = 'darkgreen', label = 'GloGEM')\n",
    "        axs[s].plot(yrs_dt[0:-1], annual_variance_OG[SSP][basin].mean(dim = 'gcm'), color = 'royalblue', label = 'OGGM')\n",
    "\n",
    "for s in range(4):  \n",
    "    axs[s].set_xlabel('Year')\n",
    "    axs[s].set_xlabel('')\n",
    "    axs[s].set_xticks([pd.to_datetime('2025'),pd.to_datetime('2050'), pd.to_datetime('2075'), pd.to_datetime('2100')], [2025, 2050, 2075, 2100])\n",
    "    if s == 0:                                                                    #Setting basin labels\n",
    "        axs[s].set_ylabel(r'  $\\sigma^2$')\n",
    "    if s != 0:\n",
    "        axs[s].set_ylabel('')\n",
    "        axs[s].set_yticklabels('')\n",
    "    \n",
    "green_patch = mpatches.Patch(color='darkgreen', label='GloGEM')\n",
    "purple_patch = mpatches.Patch(color='purple', label='PyGEM') \n",
    "blue_patch = mpatches.Patch(color='royalblue', label='OGGM')\n",
    "axs[0].legend(handles=[green_patch, purple_patch, blue_patch],bbox_to_anchor=(3.15, 1.4), ncol=3)\n",
    "plt.suptitle('Inter-Annual Variance for Projected Runoff of the '+str(basintext)+' River Basin', x=0.488, y=1.28)\n",
    "plt.title('SSP 126                          SSP 245                         SSP 370                          SSP 585', x=-1.3, y=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774862a-bd5b-4fd9-8f18-9185df036a23",
   "metadata": {},
   "source": [
    "### CSV File Read Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eda7e3-4817-4e79-a44e-beb2c1785374",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up filename to reflect what you're writing out, possibly in a nested loop\n",
    "modelnames_all = ['BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', \n",
    "                  'INM-CM4-8', 'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "basins = ['CLUTHA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3e137-b73f-4d83-934e-8c239e01a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning OGGM 2d time array into 1d df\n",
    "df = {}\n",
    "df_list = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    df[SSP] = {}\n",
    "    df_list[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        df[SSP][basin] = {}\n",
    "        df_list[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            df[SSP][basin][model] = {}\n",
    "            df_list[SSP][basin][model] = []\n",
    "            for n in range(101):\n",
    "                df[SSP][basin][model][2000+n] = pd.DataFrame(trimmed_basin_sums_monthly_OG[SSP][basin]. sel(gcm = model, time = 2000+n))\n",
    "                df_list[SSP][basin][model].append(df[SSP][basin][model][2000+n])\n",
    "                \n",
    "basin_sums_monthly_OG_df = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "     basin_sums_monthly_OG_df[SSP] = {}\n",
    "     for b, basin in enumerate(basins):\n",
    "         basin_sums_monthly_OG_df[SSP][basin] = {}\n",
    "         for m, model in enumerate(modelnames_all):\n",
    "             basin_sums_monthly_OG_df[SSP][basin][model] = pd.concat(df_list[SSP][basin][model], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d69f8-a94c-49dd-bd0c-9fb17ae5a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the GloGEM datetime index\n",
    "indices = basin_sums_monthly_glo['ssp126'][basins[0]]['BCC-CSM2-MR'][240::].index\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            glo_values = basin_sums_monthly_glo[SSP][basin][model][240::].values.flatten()\n",
    "            pygem_values = pd.DataFrame(basin_sums_monthly_py[SSP][basin].sel(model=m + 1)).values.flatten()\n",
    "            oggm_values = basin_sums_monthly_OG_df[SSP][basin][model].values.flatten()\n",
    "\n",
    "            out_df[SSP][basin][model] = pd.DataFrame(\n",
    "                {\n",
    "                    'GloGEM': glo_values,\n",
    "                    'PyGEM': pygem_values,\n",
    "                    'OGGM': oggm_values,\n",
    "                },\n",
    "                index=indices\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd38b9b-d69c-4ebf-bddd-64768203e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Runoff/RGI 18/'\n",
    "\n",
    "for SSP in out_df:\n",
    "    for basin in out_df[SSP]:\n",
    "        for GCM in out_df[SSP][basin]:\n",
    "            fname = f\"runoff_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
