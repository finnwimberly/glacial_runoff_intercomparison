{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7568d575-7931-4eca-84aa-50bcb869eb93",
   "metadata": {},
   "source": [
    "## Aggregating Net Basin Runoff-PyGem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a3ce9-d4a8-45d9-8e5a-14ecf7b16bd6",
   "metadata": {},
   "source": [
    "This notebook imports all PyGEM runoff data for RGI region 11. Using Erik Homgren's function, we sort glaciers into major river basin and sum their respective runoff values. Ultimately, the notebook produces a figure displaying the relative contributions of glacial runoff to the Rhine, Rhone, Po, and Danube river basins. This notebook is based off of a previous notebook and attempts to reduce the earlier iteration's runtime. \n",
    "\n",
    "Last Updated: 7 June 2023| FFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b9eb5a-ad68-4fd8-83c9-93846e103348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "import itertools\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec278e06-5e6e-4ebe-90f5-2ed4a30e647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the climate models used\n",
    "modelnames = ['BCC-CSM2-MR','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPs = ['ssp126','ssp245','ssp370','ssp585'] #List of all SSPs in PyGEM\n",
    "which_ssp = SSPs[0]\n",
    "\n",
    "alpine_basins = {'RHINE': '6242',\n",
    "                 'RHONE': '6243',\n",
    "                 'PO': '6241',\n",
    "                 'DANUBE':'6202'} ## GRDC Major River Basin identifiers for the 4 alpine basins we can study\n",
    "\n",
    "test_basin = alpine_basins['RHONE'] \n",
    "\n",
    "#Generic filepath to navigate to Drive folder \n",
    "fpathPy = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d82ad6-243e-4a78-a683-ef83afef2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a6430adf-5a47-4992-8c6b-04bd8018264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all runoff data, taking annual sum, and converting m^3 to km^3\n",
    "import glob   #use glob to group files by filename similarities (in this case, SSP)\n",
    "\n",
    "rf_ds = {}\n",
    "annual_rf_ds = {}\n",
    "for s, SSP in enumerate(SSPs):\n",
    "    fpath1 = '/R11_runoff_monthly_c2_ba1_1set_2000_2100-{}'.format(SSP)\n",
    "    file_pattern = f'{fpathPy + fpath1}*.nc'\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    \n",
    "    datasets = []  # Create an empty list for each SSP\n",
    "    if file_list:\n",
    "        for file in file_list:\n",
    "            with xr.open_dataset(file) as ds:\n",
    "                ds = ds.glac_runoff_monthly.load()\n",
    "                datasets.append(ds)\n",
    "    \n",
    "        combined_ds = xr.concat(datasets, dim='glacier')  # Concatenate the datasets\n",
    "        rf_ds[SSP] = combined_ds\n",
    "        annual_rf_ds[SSP] = rf_ds[SSP].resample(time='A').sum() * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7334b7bb-64be-44f7-9809-42280ed4871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "for basin, code in alpine_basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "03cc68fd-09c1-4a17-9dc5-52d23dd366bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into basins\n",
    "basin_datasets = {}\n",
    "for basin, glacier_list in basin_gls.items():\n",
    "    ## loop over them all, drop the irrelevant IDs, and concatenate the result\n",
    "    basin_datasets[basin] = {}\n",
    "    ds_list = []\n",
    "    for s, SSP in enumerate(SSPs):  \n",
    "        try:\n",
    "            ds_filtered = annual_rf_ds[SSP].where(annual_rf_ds[SSP].RGIId.isin(glacier_list), drop=True)\n",
    "            #print(ds_filtered)\n",
    "            ds_list.append(ds_filtered)\n",
    "        except ValueError: ## happens if there are no glaciers from this batch in the selected region\n",
    "            continue\n",
    "        basin_datasets[basin][SSP] = xr.concat(ds_list, dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4aeb13b4-e527-43a8-8e57-7e9a83d999dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flipping indexing (to match other models) and summing basins\n",
    "basin_sums_py = {}\n",
    "for s, SSP in enumerate(SSPs):        \n",
    "    basin_sums_py[SSP] = {}\n",
    "    for basin, glacier_list in basin_gls.items():\n",
    "        basin_sums_py[SSP][basin] = basin_datasets[basin][SSP].sum(dim='glacier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a069f3-5127-4255-8053-f9598d510cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
