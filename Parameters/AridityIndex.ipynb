{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bc0473-7715-4d53-a4de-e6e93be23adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "import csv\n",
    "\n",
    "## Generic the filepath to the main data folder\n",
    "fpath0 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/'\n",
    "fpath1 = 'Lizz Research Stuff/CSV Outputs/Initial Areas/Results_PET_PREC/'\n",
    "\n",
    "modelnames = ['BCC.BCC-CSM2-MR', 'MPI-M.MPI-ESM1-2-HR', 'MRI.MRI-ESM2-0', 'NCAR.CESM2-WACCM']\n",
    "\n",
    "scenarios = ['Ssp2p6', 'Ssp4p5', 'Ssp7p0', 'Ssp8p5']\n",
    "\n",
    "basins = {'RHINE':'6242', 'RHONE':'6243','PO':'6241', 'DANUBE':'6202', 'TITICACA':'3912', 'SANTA':'3425', \n",
    "            'OCONA':'3418', 'MAJES':'3416', 'MAGDALENA':'3227', 'AMAZON':'3203', 'YELCHO':'3429', \n",
    "            'VALDIVIA':'3428', 'SERRANO':'3426', 'RAPEL':'3423', 'PUELO':'3422', 'PASCUA':'3420', \n",
    "            'PALENA':'3419', 'HUASCO':'3412', 'COPIAPO':'3409', 'CISNES':'3408', 'BIOBIO':'3405', 'BAKER':'3404',\n",
    "            'AZOPARDO':'3403', 'AISEN':'3401', 'SANTA CRUZ':'3244', 'NEGRO':'3232', 'COLORADO':'3212', \n",
    "            'CHICO':'3209', 'TORNEALVEN':'6255', 'THJORSA':'6254', 'OLFUSA':'6237', 'LULEALVEN':'6227', \n",
    "            'KUBAN':'6223', 'KALIXALVEN':'6219', 'GLOMAA':'6213', 'DRAMSELVA':'6209', 'SVARTA':'6110', \n",
    "            'LAGARFLJOT':'6104', 'JOKULSA A FJOLLUM':'6101', 'CLUTHA':'5406', 'YUKON':'4435', 'TAKU':'4431', \n",
    "             'SUSITNA':'4430','STIKINE':'4428', 'SKEENA':'4427','SKAGIT':'4426','NUSHAGAK':'4418','NASS':'4416',\n",
    "            'KUSKOKWIM':'4414','FRASER':'4410', 'COPPER':'4408', 'COLUMBIA':'4406', 'ALSEK':'4401', 'NELSON':'4125', \n",
    "              'MACKENZIE':'4123','COLVILLE':'4110', 'YSYK-KOL':'2919', 'UVS NUUR':'2918', 'TARIM HE':'2914', \n",
    "              'TALAS':'2913', 'LAKE BALKHASH':'2910','HAR US NUUR':'2909', 'CHUY':'2905', 'ARAL SEA':'2902', \n",
    "              'YELLOW RIVER':'2434', 'MEKONG':'2421', 'KAMCHATKA':'2413', 'SALWEEN':'2319', 'IRRAWADDY':'2310', \n",
    "              'INDUS':'2309', 'GANGES':'2306','BRAHMAPUTRA':'2302', 'OB':'2108', 'INDIGIRKA':'2103','YANGTZE' : '2433'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd717a4-821d-400b-b117-f6fe9f4061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in files\n",
    "precip = {}\n",
    "for m, model in enumerate(modelnames):\n",
    "    precip[model[0:3]] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        precip[model[0:3]][SSP] = np.loadtxt(fpath0 + fpath1 + model + '_PREC_' + SSP + '.txt')\n",
    "\n",
    "PET = {}\n",
    "for m, model in enumerate(modelnames):\n",
    "    PET[model[0:3]] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        PET[model[0:3]][SSP] = np.loadtxt(fpath0 + fpath1 + model + '_PET_' + SSP + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c90bd48-36eb-4b38-a9a0-be3dd1d5e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(1900, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "timesteps = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Apply new index and datetime conversion\n",
    "for m, model in enumerate(modelnames):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        precip[model[0:3]][SSP] = pd.DataFrame(precip[model[0:3]][SSP])\n",
    "        precip[model[0:3]][SSP].index = basins\n",
    "        precip[model[0:3]][SSP].columns = timesteps\n",
    "\n",
    "        PET[model[0:3]][SSP] = pd.DataFrame(PET[model[0:3]][SSP])\n",
    "        PET[model[0:3]][SSP].index = basins\n",
    "        PET[model[0:3]][SSP].columns = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d96444-38a5-42fa-9865-912b3a09c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining how many PETs are negative\n",
    "negative_PETs = {}\n",
    "percent_PET_negative = {}\n",
    "for m, model in enumerate(modelnames):\n",
    "    negative_PETs[model[0:3]] = {}\n",
    "    percent_PET_negative[model[0:3]] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        negative_PETs[model[0:3]][SSP] = PET[model[0:3]][SSP][PET[model[0:3]][SSP]<0]\n",
    "        negative_PETs[model[0:3]][SSP] = negative_PETs[model[0:3]][SSP].stack().reset_index()\n",
    "        #negative_PETs[model[0:3]][SSP] = negative_PETs[model[0:3]][SSP].stack().reset_index()\n",
    "        negative_PETs[model[0:3]][SSP].columns = ['Basins', 'Date', 'PET']\n",
    "        percent_PET_negative[model[0:3]][SSP] = (len(negative_PETs[model[0:3]][SSP])/(2412 * 75)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa5bc0f-4dee-4191-badf-777a5f1a1fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC.BCC-CSM2-MR Ssp2p6 20.137092316196796\n",
      "BCC.BCC-CSM2-MR Ssp4p5 19.974018794914315\n",
      "BCC.BCC-CSM2-MR Ssp7p0 19.84466556108347\n",
      "BCC.BCC-CSM2-MR Ssp8p5 19.755113322277502\n",
      "MPI-M.MPI-ESM1-2-HR Ssp2p6 15.088999447208403\n",
      "MPI-M.MPI-ESM1-2-HR Ssp4p5 15.02377003869541\n",
      "MPI-M.MPI-ESM1-2-HR Ssp7p0 14.906578220011054\n",
      "MPI-M.MPI-ESM1-2-HR Ssp8p5 14.878938640132668\n",
      "MRI.MRI-ESM2-0 Ssp2p6 16.671641791044774\n",
      "MRI.MRI-ESM2-0 Ssp4p5 16.47705914870094\n",
      "MRI.MRI-ESM2-0 Ssp7p0 16.34825870646766\n",
      "MRI.MRI-ESM2-0 Ssp8p5 16.206744057490326\n",
      "NCAR.CESM2-WACCM Ssp2p6 15.55721393034826\n",
      "NCAR.CESM2-WACCM Ssp4p5 15.440022111663904\n",
      "NCAR.CESM2-WACCM Ssp7p0 15.384190160309563\n",
      "NCAR.CESM2-WACCM Ssp8p5 15.163626312880044\n"
     ]
    }
   ],
   "source": [
    "for m, model in enumerate(modelnames):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        print(model, SSP, percent_PET_negative[model[0:3]][SSP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1228653-7ca6-4e60-8bce-2a5c4c5561d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up time ranges\n",
    "start_1900 = pd.to_datetime(\"1900-01-01\")\n",
    "end_2000 = pd.to_datetime(\"1999-12-31\")\n",
    "start_2000 = pd.to_datetime(\"2000-01-01\")\n",
    "end_2100 = pd.to_datetime(\"2100-12-31\")\n",
    "\n",
    "# Initialize dictionaries to store summed values\n",
    "PET_avg_1900_2000 = {}\n",
    "PET_avg_2000_2100 = {}\n",
    "precip_avg_1900_2000 = {}\n",
    "precip_avg_2000_2100 = {}\n",
    "\n",
    "# Loop through models and scenarios\n",
    "for m, model in enumerate(modelnames):\n",
    "    PET_avg_1900_2000[model[0:3]] = {}\n",
    "    PET_avg_2000_2100[model[0:3]] = {}\n",
    "    precip_avg_1900_2000[model[0:3]] = {}\n",
    "    precip_avg_2000_2100[model[0:3]] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        # Filter columns for the period 1900-2000\n",
    "        columns_1900_2000 = [col for col in PET[model[0:3]][SSP].columns if start_1900 <= pd.to_datetime(col) <= end_2000]\n",
    "        # Sum values for the period 1900-2000\n",
    "        PET_avg_1900_2000[model[0:3]][SSP] = pd.DataFrame({\"Avg_1900_1999\":PET[model[0:3]][SSP][columns_1900_2000].sum(axis = 1)})/1200\n",
    "\n",
    "        columns_2000_2100 = [col for col in PET[model[0:3]][SSP].columns if start_2000 <= pd.to_datetime(col) <= end_2100]\n",
    "        PET_avg_2000_2100[model[0:3]][SSP] = pd.DataFrame({\"Avg_2000_2100\": PET[model[0:3]][SSP][columns_2000_2100].sum(axis = 1)})/1212\n",
    "\n",
    "        columns_1900_2000 = [col for col in precip[model[0:3]][SSP].columns if start_1900 <= pd.to_datetime(col) <= end_2000]\n",
    "        # Avg values for the period 2000-2100\n",
    "        precip_avg_1900_2000[model[0:3]][SSP] = pd.DataFrame({\"Avg_1900_1999\":precip[model[0:3]][SSP][columns_1900_2000].sum(axis = 1)})/1200\n",
    "\n",
    "        columns_2000_2100 = [col for col in PET[model[0:3]][SSP].columns if start_2000 <= pd.to_datetime(col) <= end_2100]\n",
    "        precip_avg_2000_2100[model[0:3]][SSP] = pd.DataFrame({\"Avg_2000_2100\":precip[model[0:3]][SSP][columns_2000_2100].sum(axis = 1)})/1212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d63e9b3-7877-485b-a25c-25484249a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "aridity_index_20thCent = {}\n",
    "aridity_index_21stCent = {}\n",
    "for m, model in enumerate(modelnames):\n",
    "    aridity_index_20thCent[model[0:3]] = {}\n",
    "    aridity_index_21stCent[model[0:3]] = {}\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "         aridity_index_20thCent[model[0:3]][SSP] = precip_avg_1900_2000[model[0:3]][SSP] / PET_avg_1900_2000[model[0:3]][SSP]\n",
    "         aridity_index_21stCent[model[0:3]][SSP] = precip_avg_2000_2100[model[0:3]][SSP] / PET_avg_2000_2100[model[0:3]][SSP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5fbe6d-c084-4c61-98f9-d7cb01780234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I want to scale can use this\n",
    "#For now values look ok\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# aridity_index = {}\n",
    "# for m, model in enumerate(modelnames):\n",
    "#     aridity_index[model[0:3]] = {}\n",
    "#     for s, SSP in enumerate(scenarios):\n",
    "\n",
    "#         temp_df =  (precip[model[0:3]][SSP] / PET[model[0:3]][SSP])\n",
    "#         scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "#         aridity_index[model[0:3]][SSP] = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=basins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254a742a-8ff7-4efd-864d-dc397c4c836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Basin Aridity/'\n",
    "\n",
    "models = ['BCC', 'MPI', 'MRI', 'NCA']\n",
    "\n",
    "for m, GCM in enumerate(models):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        fname = f\"Aridity_Index_Monthly{GCM}_{SSP}.csv\"\n",
    "\n",
    "        # Define the full path of the output file\n",
    "        output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        # Save the DataFrame as CSV\n",
    "        aridity_index_21stCent[GCM][SSP].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4fb5c66-010f-43ba-b3d6-2c00f72f96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making df which contains all values to calulate an average\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "GCM_SSP_indices = []\n",
    "for m, GCM in enumerate(models):\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        column_name = f'{GCM}_{SSP}'\n",
    "        GCM_SSP_indices.append(column_name)\n",
    "\n",
    "# Loop through models and scenarios\n",
    "for model_key in aridity_index_21stCent.keys():\n",
    "    for s, SSP in enumerate(scenarios):\n",
    "        # Extract the dataframe for the current model and scenario\n",
    "        current_df = aridity_index_21stCent[model_key][SSP]\n",
    "        \n",
    "        # Add the current_df as a new column in the combined_df\n",
    "        if combined_df.empty:\n",
    "            combined_df = current_df\n",
    "        else:\n",
    "            combined_df = pd.concat([combined_df, current_df], axis=1)\n",
    "\n",
    "# Set the column names of the combined_df to be the values in GCM_SSP_indices\n",
    "combined_df.columns = GCM_SSP_indices\n",
    "\n",
    "# Calculate the average of the aridity index across the columns\n",
    "average_aridity_index = combined_df.mean(axis=1)\n",
    "\n",
    "# Add the average as a new column in the combined_df\n",
    "combined_df['Average_Aridity_Index'] = average_aridity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e876bd1-eb5e-4825-9d84-9b20e88f93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"Aridity_Index_Avg.csv\"\n",
    "\n",
    "# Define the full path of the output file\n",
    "output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "average_aridity_index.to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f66b9-e8b7-47eb-8f9e-ded511b72f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
