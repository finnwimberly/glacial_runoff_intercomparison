{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89e01dc-c952-4547-b9cd-1bb6cf56002d",
   "metadata": {},
   "source": [
    "## Aggregation of GloGEM runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998c010d-efcd-4eec-949e-df12da9fccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "## Generic the filepath to the main data folder\n",
    "fpath0 = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/Runoff-intercomparison/GloGEM-output/RGI06-Iceland/files/'  \n",
    "\n",
    "#All of the climate models used\n",
    "modelnames = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "SSPpaths = ['ssp126','ssp245','ssp370','ssp585']   #Specifiying the SSP\n",
    "#SSPs = ['ssp119','ssp126','ssp245','ssp370','ssp585'] #Use a different path as we have all 5 ssps for volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a112ff9-d7e9-4c57-a016-2b597b1eac0a",
   "metadata": {},
   "source": [
    "### Loading/Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e6d6ac-437f-45ee-9838-e18941ff91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_discharges = [[] for _ in SSPpaths]\n",
    "\n",
    "for s, SSPpath in enumerate(SSPpaths):\n",
    "    model_discharges = []\n",
    "    for modelname in modelnames:\n",
    "        temp_df = pd.read_csv(fpath0 + modelname + '/' + SSPpaths[s]  + '/' + 'Iceland_Discharge_r1.dat', sep='\\s+', header=None, skiprows=1, index_col=0)\n",
    "        model_discharges.append(temp_df)\n",
    "    all_discharges[s] = model_discharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4c6e77-c2f6-42d7-aa51-6e3bffefd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index using pandas date_range function\n",
    "start_date = datetime.date(1980, 1, 1)\n",
    "end_date = datetime.date(2100, 12, 1)\n",
    "new_indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "# Apply new index and datetime conversion\n",
    "for s, SSPpath_discharges in enumerate(all_discharges):\n",
    "    for m, discharge_df in enumerate(SSPpath_discharges):\n",
    "        all_discharges[s][m].columns = new_indices\n",
    "        all_discharges[s][m].columns = pd.to_datetime(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8664ddd-6a73-450a-80a6-fd933b8f61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only use  initial area to compute runoff\n",
    "# We also convert km^2 to m^2\n",
    "\n",
    "runoff = {s: {m: None for m in modelnames} for s in SSPpaths}  # create nested dictionary indexed by model name and ssp\n",
    "all_areas = {s: {m: None for m in modelnames} for s in SSPpaths}\n",
    "\n",
    "for s, SSP in enumerate(SSPpaths):\n",
    "    for m, modelname in enumerate(modelnames):\n",
    "        temp_df = pd.read_csv(fpath0 + modelname + '/' + SSPpaths[s] + '/' + 'Iceland_Area_r1.dat', sep='\\s+', index_col=\"ID\")\n",
    "        all_areas[SSP][modelname] = temp_df\n",
    "        \n",
    "        temp_df = all_areas[SSP][modelname].iloc[:, 0].values.repeat(all_discharges[s][m].shape[1]).reshape(all_discharges[s][m].shape)\n",
    "        initial_areas = pd.DataFrame(temp_df, index=all_discharges[s][m].index, columns=all_discharges[s][m].columns).mul(1e6)\n",
    "        runoff[SSP][modelname] = pd.concat([initial_areas * all_discharges[s][m]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5b4d1bd-842b-42a8-bc19-deeab9f6f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "annualrunoff = {s: {m: None for m in modelnames} for s in SSPpaths}\n",
    "for s, m in itertools.product(SSPpaths, modelnames):\n",
    "    annualrunoff[s][m] = runoff[s][m].transpose().resample('A').sum() * 1e-9  #m^3 to km^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738e377f-7373-41fb-8b98-5f834e34b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    # fpath = './data/rgi_ids_per_basin.json'\n",
    "    fpath = '/Users/finnwimberly/Library/CloudStorage/GoogleDrive-fwimberly@middlebury.edu/My Drive/Lizz Research Stuff/rgi_ids_per_basin.json'  \n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e346c3-ad9c-46ec-b703-00248dbfc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_basin(basin_RGI_list, runoff_data):\n",
    "    # Create new list to match our RGI formatting\n",
    "    new_basin_list = [int(str(x)[-5:]) for x in basin_RGI_list]\n",
    "    runoff_data = runoff_data.transpose()\n",
    "    \n",
    "    #TODO: create list of glaciers within a basin that are not included in GloGEM output\n",
    "    # Filter new_basin_list to keep only the indexes present in the DataFrame\n",
    "    new_basin_list = [x for x in new_basin_list if x in runoff_data.index]\n",
    "    \n",
    "    # Extract glaciers contained in the list from original df and create a new df\n",
    "    new_df = runoff_data.loc[new_basin_list].copy()\n",
    "    \n",
    "    # Sum the values of the glaciers within the basin\n",
    "    summed_basin_runoff = new_df.sum()\n",
    "    #print(summed_basin_runoff)\n",
    "    \n",
    "    return summed_basin_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4f3f69c-42b8-44e6-b405-706af2d64e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the aggregated basin data\n",
    "\n",
    "Alpine_basins = {'THJORSA':'6254', 'OLFUSA':'6237', 'SVARTA':'6110', 'LAGARFLJOT':'6104', 'JOKULSA A FJOLLUM':'6101'}\n",
    "\n",
    "basins = ['THJORSA', 'OLFUSA', 'SVARTA', 'LAGARFLJOT', 'JOKULSA A FJOLLUM']\n",
    "\n",
    "modelnames_glo = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basin_sums_glo = {}\n",
    "basin_sums_monthly_glo = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    basin_sums_glo[SSP] = {}\n",
    "    basin_sums_monthly_glo[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        basin_sums_glo[SSP][basin] = {}\n",
    "        basin_sums_monthly_glo[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_glo):\n",
    "            basin_sums_glo[SSP][basin][model] = sum_basin(select_glaciers_json(Alpine_basins[basin]), annualrunoff[SSP][model]) \n",
    "            basin_sums_monthly_glo[SSP][basin][model] = sum_basin(select_glaciers_json(Alpine_basins[basin]), runoff[SSP][model].transpose()*1e-9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9284c-3254-4d2c-953d-70b3e82e41f3",
   "metadata": {},
   "source": [
    "### CSV Readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e80fd00-67e2-4f33-bbdb-48f7a170c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up filename to reflect what you're writing out, possibly in a nested loop\n",
    "modelnames_all = ['BCC-CSM2-MR', 'CESM2', 'CESM2-WACCM', 'EC-Earth3', 'EC-Earth3-Veg', 'FGOALS-f3-L', 'GFDL-ESM4', \n",
    "                  'INM-CM4-8', 'INM-CM5-0', 'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorESM2-MM']\n",
    "\n",
    "scenarios = ['ssp126','ssp245','ssp370','ssp585']\n",
    "\n",
    "basins = ['THJORSA', 'OLFUSA', 'SVARTA', 'LAGARFLJOT', 'JOKULSA A FJOLLUM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4dcb5c4-7a6d-4968-a620-c6d3c49efd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the GloGEM datetime index\n",
    "indices = basin_sums_monthly_glo[SSP][basin][model][240::].index\n",
    "\n",
    "#Creating dataframes of SSP, basin, and GCM containing all 3 global glacier models\n",
    "out_df = {}\n",
    "for s, SSP in enumerate(scenarios):\n",
    "    out_df[SSP] = {}\n",
    "    for b, basin in enumerate(basins):\n",
    "        out_df[SSP][basin] = {}\n",
    "        for m, model in enumerate(modelnames_all):\n",
    "            glo_values = basin_sums_monthly_glo[SSP][basin][model][240::].values.flatten()\n",
    "\n",
    "            out_df[SSP][basin][model] = pd.DataFrame(\n",
    "                {\n",
    "                    'GloGEM': glo_values,\n",
    "                    \n",
    "                },\n",
    "                index=indices\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9566bccd-8130-4e5e-93d1-0a89f7a52b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the CSV files\n",
    "output_dir = '/Users/finnwimberly/Desktop/Lizz Research/CSV Outputs/Load Separate/RGI 06/GloGEM/'\n",
    "\n",
    "for SSP in out_df:\n",
    "    for basin in out_df[SSP]:\n",
    "        for GCM in out_df[SSP][basin]:\n",
    "            fname = f\"runoff_{GCM}_{SSP}_{basin}.csv\"\n",
    "\n",
    "            # Define the full path of the output file\n",
    "            output_path = os.path.join(output_dir, fname)\n",
    "\n",
    "            # Save the DataFrame as CSV\n",
    "            out_df[SSP][basin][GCM].to_csv(output_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af762093-bc0b-42b8-a9b3-ab0c0ae01c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
